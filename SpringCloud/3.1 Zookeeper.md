# Zookeeper

 [【尚硅谷】2021最新版Zookeeper 3.5.7版本教程](https://www.bilibili.com/video/BV1to4y1C7gw?p=1)

## 1. 概述

​	Zookeeper 是一个开源的分布式的，为分布式框架提供协调服务的 Apache 项目。

## 2. Zookeeper 工作机制

> Zookeeper从设计模式角度来理解：是一个基 于观察者模式设计的分布式服务管理框架，它负 责 存储和管理大家都关心的数据，然 后接受观察者的 注 册，一旦这些数据的状态发生变化，Zookeeper 就 将负责通知已经在Zookeeper上注册的那些观察 者做出相应的反应。

## 3. 特点

1）Zookeeper：一个领导者（Leader），多个跟随者（Follower）组成的集群。 

2）集群中只要有半数以上节点存活，Zookeeper集群就能正常服务。所 以Zookeeper适合安装奇数台服务器。 

3）全局数据一致：每个Server保存一份相同的数据副本，Client无论连接到哪个Server，数据都是一致的。 

4）更新请求顺序执行，来自同一个Client的更新请求按其发送顺序依次执行。 

5）数据更新原子性，一次数据更新要么成功，要么失败。

6）实时性，在一定时间范围内，Client能读到最新数据。

## 4. 应用场景

​		提供的服务包括：统一命名服务、统一配置管理、统一集群管理、服务器节点动态上下 线、软负载均衡等。

### 1.  统一命名服务

​		在分布式环境下，经常需要对应用/服 务进行统一命名，便于识别。 

​		例如：IP不容易记住，而域名容易记住。

### 2. 统一配置管理

​		1）分布式环境下，配置文件同步非常常见。

​			（1）一般要求一个集群中，所有节点的配置信息是 一致的，比如 Kafka 集群。

​			（2）对配置文件修改后，希望能够快速同步到各个 节点上。

​		2）配置管理可交由ZooKeeper实现。

​			（1）可将配置信息写入ZooKeeper上的一个Znode。

​			（2）各个客户端服务器监听这个Znode。 

​			（3）一 旦Znode中的数据被修改，ZooKeeper将通知 各个客户端服务器。

​				![image-20210708142019427](https://gitee.com/jiao_qianjin/zhishiku/raw/master/img/20210708142027.png) 

### 3. 统一集群管理

​	1）分布式环境中，实时掌握每个节点的状态是必要的。 

​		（1）可根据节点实时状态做出一些调整。

​	2）ZooKeeper可以实现实时监控节点状态变化 

​		（1）可将节点信息写入ZooKeeper上的一个ZNode。 

​		（2）监听这个ZNode可获取它的实时状态变化。

### 4. 服务器动态上下线

​		客户端能实时洞察到服务 器上下线的变化

![image-20210708142239752](https://gitee.com/jiao_qianjin/zhishiku/raw/master/img/20210708142239.png)

### 5. 软负载均衡

​		在Zookeeper中记录每台服务器的访问数，让访问数最少的服务器去处理最新的客户端请求

![image-20210708142326782](https://gitee.com/jiao_qianjin/zhishiku/raw/master/img/20210708142326.png) 

## 5. 配置参数解读

​	Zookeeper中的配置文件zoo.cfg中参数含义解读如下：

​		1．tickTime =2000：通信心跳数，Zookeeper服务器与客户端心跳时间，单位毫秒

​			Zookeeper使用的基本时间，服务器之间或客户端与服务器之间维持心跳的时间间隔，也就是每个tickTime时间就会发送一个心跳，时间单位为毫秒。

​			它用于心跳机制，并且设置最小的session超时时间为两倍心跳时间。(session的最小超时时间是2*tickTime)

​		2．initLimit =10：LF初始通信时限

​			集群中的Follower跟随者服务器与Leader领导者服务器之间初始连接时能容忍的最多心跳数（tickTime的数量），用它来限定集群中的Zookeeper服务器连			接到Leader的时限。

​		3．syncLimit =5：LF同步通信时限

​			集群中Leader与Follower之间的最大响应时间单位，假如响应超过syncLimit * tickTime，Leader认为Follwer死掉，从服务器列表中删除Follwer。

​		4．dataDir：数据文件目录+数据持久化路径

​			主要用于保存Zookeeper中的数据。

​		5．clientPort =2181：客户端连接端口

​			监听客户端连接的端口。

## 6. 选举机制（![img](https://gitee.com/jiao_qianjin/zhishiku/raw/master/img/20210708150854.png)）

### 1. 第一次启动

![image-20210708142902940](https://gitee.com/jiao_qianjin/zhishiku/raw/master/img/20210708142903.png)

（1）服务器1启 动，发起一次选举。服务器1投自己一票。此时服务器1票数一票，不够半数以上（3票），选举无法完成，服务器1状态保持为 LOOKING；

 （2）服务器2启动，再发起一次选举。服务器1和2分别投自己一票并交换选票信息：此时服务器1发现服务器2的myid比自己目前投票推举的（服务器1） 大，更改选票为推举服务器2。此时服务器1票数0票，服务器2票数2票，没有半数以上结果，选举无法完成，服务器1，2状态保持LOOKING 

（3）服务器3启动，发起一次选举。此时服务器1和2都会更改选票为服务器3。此次投票结果：服务器1为0票，服务器2为0票，服务器3为3票。此时服 务器3的票数已经超过半数，服务器3当选Leader。服务器1，2更改状态为FOLLOWING，服务器3更改状态为LEADING； LOOKING LOOKING 

（4）服务器4启动，发起一次选举。此时服务器1，2，3已经不是LOOKING状态，不会更改选票信息。交换选票信息结果：服务器3为3票，服务器4为 1票。此时服务器4服从多数，更改选票信息为服务器3，并更改状态为FOLLOWING； 

（5）服务器5启动，同4一样当小弟。

**选举规则：投票过半数时，服务器 id 大的胜出**

### 2. 非第一次启动

![image-20210708143616394](https://gitee.com/jiao_qianjin/zhishiku/raw/master/img/20210708143616.png)

（1）当ZooKeeper集群中的一台服务器出现以下两种情况之一时，就会开始进入Leader选举：

​		 • 服务器初始化启动。

​		 • 服务器运行期间无法和Leader保持连接。 

（2）而当一台机器进入Leader选举流程时，当前集群也可能会处于以下两种状态：

​		 • 集群中本来就已经存在一个Leader。 对于第一种已经存在Leader的情况，机器试图去选举Leader时，会被告知当前服务器的Leader信息，对于该机器来说，仅仅需要和Leader机器建立连 接，并进行状态同步即可。 

​		**• 集群中确实不存在Leader。**

​			 假设ZooKeeper由5台服务器组成，SID分别为1、2、3、4、5，ZXID分别为8、8、8、7、7，并且此时SID为3的服务器是Leader。某一时刻， 3和5服务器出现故障，因此开始进行Leader选举。 （EPOCH，ZXID，SID ）

 SID为1、2、4的机器投票情况： 

| （EPOCH，ZXID，SID ） | （EPOCH，ZXID，SID ） | （EPOCH，ZXID，SID ） |
| --------------------- | --------------------- | --------------------- |
| （1，8，1）           | （1，8，2）           | （1，7，4）           |

 **选举Leader规则：** 

​	**①EPOCH大的直接胜出** 

​	**②EPOCH相同，事务id大的胜出**

​	**③事务id相同，服务器id大的胜出**

## 7. 节点类型

持久（Persistent）：客户端和服务器端断开连接后，创建的节点不删除

短暂（Ephemeral）：客户端和服务器端断开连接后，创建的节点自己删除

（1）持久化目录节点 

​		客户端与Zookeeper断开连接后，该节点依旧存在

（2）持久化顺序编号目录节点 

​		客户端与Zookeeper断开连接后，该节点依旧存 在，只是Zookeeper给该节点名称进行顺序编号

（3）临时目录节点 

​		客户端与Zookeeper断开连接后，该节点被删除

（4）临时顺序编号目录节点 

​		客户端与 Zookeeper 断开连接后 ， 该 节 点 被 删 除 ， 只 是 Zookeeper给该节点名称进行顺序编号。

## 8. 监听器原理

​		客户端注册监听它关心的目录节点，当目录节点发生变化（数据改变、节点删除、子目 录节点增加删除）时，ZooKeeper 会通知客户端。监听机制保证 ZooKeeper 保存的任何的数 据的任何改变都能快速的响应到监听了该节点的应用程序。

1、监听原理详解

​	1）首先要有一个main()线程 

​	2）在main线程中创建Zookeeper客户端，这时就会创建两个线 程，一个负责网络连接通信（connet），一个负责监听（listener）。

​	3）通过connect线程将注册的监听事件发送给Zookeeper。 

​	4）在Zookeeper的注册监听器列表中将注册的监听事件添加到列表中。 

​	5）Zookeeper监听到有数据或路径变化，就会将这个消息发送给listener线程。

​	6）listener线程内部调用了process()方法。

2、常见的监听

​	1）监听节点数据的变化 

```sh
get path [watch] 
```

​	2）监听子节点增减的变化

```sh
 ls path [watch]
```

![image-20210708144314419](https://gitee.com/jiao_qianjin/zhishiku/raw/master/img/20210708144314.png)

## 9. 客户端向服务端写数据流程

### 1. 写流程之写入请求直接发送给Leader节点

![image-20210708144437218](https://gitee.com/jiao_qianjin/zhishiku/raw/master/img/20210708144437.png) 

### 3. 写流程之写入请求发送给follower节点

![image-20210708144954891](https://gitee.com/jiao_qianjin/zhishiku/raw/master/img/20210708144954.png)

## 10. 分布式锁

### 1. Java API 实现

#### 1. 原理

> 什么叫做分布式锁呢？ 比如说"进程 1"在使用该资源的时候，会先去获得锁，"进程 1"获得锁以后会对该资源保持独占，这样其他进程就无法访问该资源，"进程 1"用完该资源以后就将锁释放掉，让其 他进程来获得锁，那么通过这个锁机制，我们就能保证了分布式系统中多个进程能够有序的 访问该临界资源。那么我们把这个分布式环境下的这个锁叫作分布式锁。

![image-20210708145511082](https://gitee.com/jiao_qianjin/zhishiku/raw/master/img/20210708145511.png)

#### 2. 代码实现

```java
package com.marchsoft.case2;

import org.apache.zookeeper.*;
import org.apache.zookeeper.data.Stat;

import java.io.IOException;
import java.util.Collections;
import java.util.List;
import java.util.concurrent.CountDownLatch;

/**
 * Description： zookeeper 分布式锁
 *
 * @author jiaoqianjin
 * Date: 2021/7/8 10:10
 **/

public class DistributeLock {
    /**
     * zookeeper server 列表
     */
    private String connectString = "zookeeper1:2181,zookeeper2:2181,zookeeper2:2181";
    /**
     * 超时时间
     */
    private int sessionTimeout = 2000;
    private ZooKeeper zk;
    private String rootNode = "locks";
    private String subNode = "seq-";
    /**
     * 当前 client 等待的子节点
     */
    private String waitPath;
    /**
     * ZooKeeper 连接
     */
    private CountDownLatch connectLatch = new CountDownLatch(1);
    /**
     * ZooKeeper 节点等待
     */
    private CountDownLatch waitLatch = new CountDownLatch(1);
    /**
     * 当前 client 创建的子节点
     */
    private String currentNode;

    /**
     * 功能描述: 和 zk 服务建立连接，并创建根节点
     *
     * @author jiaoqianjin
     * @date 2021/7/8
     */
    public DistributeLock() throws IOException, InterruptedException, KeeperException {
        zk = new ZooKeeper(connectString, sessionTimeout, new Watcher() {
            @Override
            public void process(WatchedEvent event) {
                // 连接建立时, 打开 latch, 唤醒 wait 在该 latch 上的线程
                if (event.getState() == Event.KeeperState.SyncConnected) {
                    connectLatch.countDown();
                }
                // 发生了 waitPath 的删除事件
                if (event.getType() == Event.EventType.NodeDeleted && event.getPath().equals(waitPath)) {
                    waitLatch.countDown();
                }
            }
        });
        // 等待连接建立
        connectLatch.await();
        //获取根节点状态
        Stat stat = zk.exists("/" + rootNode, false);
        //如果根节点不存在，则创建根节点，根节点类型为永久节点
        if (stat == null) {
            System.out.println("根节点不存在");
            zk.create("/" + rootNode, new byte[0], ZooDefs.Ids.OPEN_ACL_UNSAFE, CreateMode.PERSISTENT);
        }
    }

    /**
     * 功能描述: 加锁方法
     *
     * @author jiaoqianjin
     * @date 2021/7/8
     */
    public void zkLock() {
        try {
            //在根节点下创建临时顺序节点，返回值为创建的节点路径
            currentNode = zk.create("/" + rootNode + "/" + subNode, null, ZooDefs.Ids.OPEN_ACL_UNSAFE,
                    CreateMode.EPHEMERAL_SEQUENTIAL);
            // wait 一小会, 让结果更清晰一些
            Thread.sleep(10);
            // 注意, 没有必要监听"/locks"的子节点的变化情况
            List<String> childrenNodes = zk.getChildren("/" + rootNode, false);
            // 列表中只有一个子节点, 那肯定就是 currentNode , 说明client 获得锁
            if (childrenNodes.size() == 1) {
                return;
            } else {
                //对根节点下的所有临时顺序节点进行从小到大排序
                Collections.sort(childrenNodes);
                //当前节点名称
                String thisNode = currentNode.substring(("/" + rootNode + "/").length());
                //获取当前节点的位置
                int index = childrenNodes.indexOf(thisNode);
                if (index == -1) {
                    System.out.println("数据异常");
                } else if (index == 0) {
                    // index == 0, 说明 thisNode 在列表中最小, 当前client 获得锁
                    return;
                } else {
                    // 获得排名比 currentNode 前 1 位的节点
                    this.waitPath = "/" + rootNode + "/" + childrenNodes.get(index - 1);
                    // 在 waitPath 上注册监听器, 当 waitPath 被删除时,zookeeper 会回调监听器的 process 方法
                    zk.getData(waitPath, true, new Stat());
                    //进入等待锁状态
                    waitLatch.await();
                    return;
                }
            }
        } catch (KeeperException e) {
            e.printStackTrace();
        } catch (InterruptedException e) {
            e.printStackTrace();
        }
    }

    /**
     * 功能描述: 解锁方法
     *
     * @author jiaoqianjin
     * @date 2021/7/8
     */
    public void zkUnlock() {
        try {
            zk.delete(this.currentNode, -1);
        } catch (Exception e) {
            e.printStackTrace();
        }
    }
}
```

#### 3. 测试

```java
package com.marchsoft.case2;

import org.apache.zookeeper.KeeperException;

import java.io.IOException;

/**
 * Description：
 *
 * @author jiaoqianjin
 * Date: 2021/7/8 10:32
 **/

public class DistributeLockTest {
    public static void main(String[] args) throws InterruptedException, IOException, KeeperException {
        // 创建分布式锁 1
        final DistributeLock lock1 = new DistributeLock();
        // 创建分布式锁 2
        final DistributeLock lock2 = new DistributeLock();
        new Thread(new Runnable() {
            @Override
            public void run() {
                // 获取锁对象
                try {
                    lock1.zkLock();
                    System.out.println("线程 1 获取锁");
                    Thread.sleep(5 * 1000);
                    lock1.zkUnlock();
                    System.out.println("线程 1 释放锁");
                } catch (Exception e) {
                    e.printStackTrace();
                }
            }
        }).start();

        new Thread(new Runnable() {
            @Override
            public void run() {
                // 获取锁对象
                try {
                    lock2.zkLock();
                    System.out.println("线程 2 获取锁");
                    Thread.sleep(5 * 1000);
                    lock2.zkUnlock();
                    System.out.println("线程 2 释放锁");
                } catch (Exception e) {
                    e.printStackTrace();
                }
            }
        }).start();
    }
}

```

#### 4. 结果

![image-20210708145754376](https://gitee.com/jiao_qianjin/zhishiku/raw/master/img/20210708145754.png) 

### 2. Curator 框架实现分布式锁案例

#### 1）原生的 Java API 开发存在的问题 

（1）会话连接是异步的，需要自己去处理。比如使用 CountDownLatch 

（2）Watch 需要重复注册，不然就不能生效 

（3）开发的复杂性还是比较高的 

（4）不支持多节点删除和创建。需要自己去递归 

#### 2）文档

Curator 是一个专门解决分布式锁的框架，解决了原生 JavaAPI 开发分布式遇到的问题。

 	官方文档：https://curator.apache.org/index.html 

#### 3）Curator 案例实操

##### 1. 添加依赖

```xml
<dependency>
 <groupId>org.apache.curator</groupId>
 <artifactId>curator-framework</artifactId>
 <version>4.3.0</version>
</dependency>
<dependency>
 <groupId>org.apache.curator</groupId>
 <artifactId>curator-recipes</artifactId>
 <version>4.3.0</version>
</dependency>
<dependency>
 <groupId>org.apache.curator</groupId>
 <artifactId>curator-client</artifactId>
 <version>4.3.0</version>
</dependency>
```

##### 2. 代码实现

```java
package com.marchsoft.case3;

import org.apache.curator.RetryPolicy;
import org.apache.curator.framework.CuratorFramework;
import org.apache.curator.framework.CuratorFrameworkFactory;
import org.apache.curator.framework.recipes.locks.InterProcessLock;
import org.apache.curator.framework.recipes.locks.InterProcessMutex;
import org.apache.curator.retry.ExponentialBackoffRetry;

/**
 * Description：
 *
 * @author jiaoqianjin
 * Date: 2021/7/8 10:38
 **/

public class CuratorLockTest {
    private String rootNode = "/locks";
    /**
     * zookeeper server 列表
     */
    private String connectString =
            "zookeeper:2181";
    /**
     * connection 超时时间
     */
    private int connectionTimeout = 2000;
    /**
     * session 超时时间
     */
    private int sessionTimeout = 2000;

    public static void main(String[] args) {
        new CuratorLockTest().test();
    }

    /**
     * 测试
     */
    private void test() {
        // 创建分布式锁 1
        final InterProcessLock lock1 = new InterProcessMutex(getCuratorFramework(), rootNode);
        // 创建分布式锁 2
        final InterProcessLock lock2 = new InterProcessMutex(getCuratorFramework(), rootNode);
        new Thread(new Runnable() {
            @Override
            public void run() {
                // 获取锁对象
                try {
                    lock1.acquire();
                    System.out.println("线程 1 获取锁");
                    // 测试锁重入
                    lock1.acquire();
                    System.out.println("线程 1 再次获取锁");
                    Thread.sleep(5 * 1000);
                    lock1.release();
                    System.out.println("线程 1 释放锁");
                    lock1.release();
                    System.out.println("线程 1 再次释放锁");
                } catch (Exception e) {
                    e.printStackTrace();
                }
            }
        }).start();
        new Thread(new Runnable() {
            @Override
            public void run() {
                // 获取锁对象
                try {
                    lock2.acquire();
                    System.out.println("线程 2 获取锁");
                    // 测试锁重入
                    lock2.acquire();
                    System.out.println("线程 2 再次获取锁");
                    Thread.sleep(5 * 1000);
                    lock2.release();
                    System.out.println("线程 2 释放锁");
                    lock2.release();
                    System.out.println("线程 2 再次释放锁");
                } catch (Exception e) {
                    e.printStackTrace();
                }
            }
        }).start();
    }

    /**
     * 分布式锁初始化
     */
    public CuratorFramework getCuratorFramework() {
        //重试策略，初试时间 3 秒，重试 3 次
        RetryPolicy policy = new ExponentialBackoffRetry(3000, 3);
        //通过工厂创建 Curator
        CuratorFramework client = CuratorFrameworkFactory.builder()
                .connectString(connectString)
                .connectionTimeoutMs(connectionTimeout)
                .sessionTimeoutMs(sessionTimeout)
                .retryPolicy(policy).build();
        //开启连接
        client.start();
        System.out.println("zookeeper 初始化完成...");
        return client;
    }
}

```

##### 3. 运行结果

![image-20210708150810517](https://gitee.com/jiao_qianjin/zhishiku/raw/master/img/20210708150810.png) 

## 11. 面试真题

### 1 选举机制 

半数机制，超过半数的投票通过，即通过。

​	1）第一次启动选举规则： 

​		投票过半数时，服务器 id 大的胜出 

​	2）第二次启动选举规则： 

​		①EPOCH 大的直接胜出

​		 ②EPOCH 相同，事务 id 大的胜出

​		 ③事务 id 相同，服务器 id 大的胜出 

### 2 生产集群安装多少 zk 合适？ 

安装奇数台。 

生产经验： 

⚫ 10 台服务器：3 台 zk； 

⚫ 20 台服务器：5 台 zk；

⚫ 100 台服务器：11 台 zk； 

⚫ 200 台服务器：11 台 

zk 服务器台数多：好处，提高可靠性；坏处：提高通信延时 

### 3 常用命令 

| 命令基本语法 | 功能描述                                                     |
| ------------ | ------------------------------------------------------------ |
| help         | 显示所有操作命令                                             |
| ls path      | 使用 ls 命令来查看当前 znode 的子节点 [可监听] <br />-w 监听子节点变化 <br />-s 附加次级信息 |
| create       | 普通创建 <br />-s 含有序列 <br />-e 临时（重启或者超时消失） |
| get path     | 获得节点的值 [可监听] <br />-w 监听节点内容变化 <br />-s 附加次级信息 |
| set          | 设置节点的具体值                                             |
| stat         | 查看节点状态                                                 |
| delete       | 删除节点                                                     |
| deleteall    | 递归删除节点                                                 |

