# 分布式锁

## 1. 为什么需要分布式锁

**思考：Java已经为我们提供了各种锁，为什么还需要分布式锁？**

> 在单体应用开发的时候，涉及到并发的问题时候，往往会使用synchronized或者Lock的方式来解决多线程间的数据不一致等各种问题。
>
> 但是在集群的项目结构中，Synchronized就再起作用了，为什么呢？
>
> synchronized关键字的作用域其实是一个进程，在这个进程下面的所有线程都能够进行加锁。但是多进程就不行了。对于集群项目来说，每个地区都可能有一台服务器。这样不同地区服务器不一样，地址不一样，进程也不一样。因此synchronized无法保证数据的一致性。

举例：

一个电商系统，目前是一台机器部署，系统中有一个用户下订单的接口，但是用户下订单之前一定要去检查一下库存，确保库存足够了才会给用户下单。由于系统有一定的并发，所以会预先将商品的库存保存在redis中，用户下单的时候会更新redis的库存。

![image-20210718205555360](https://gitee.com/jiao_qianjin/zhishiku/raw/master/img/20210718205603.png) 

问题来了：假如某个时刻，redis里面的某个商品库存为1，此时两个请求同时到来，其中一个请求执行到上图的第3步，更新数据库的库存为0，但是第4步还没有执行。而另外一个请求执行到了第2步，发现库存还是1，就继续执行第3步。这样的结果，是导致卖出了2个商品，然而其实库存只有1个。

解决方案：使用Java提供的synchronized或者Lock来锁住2、3、4步，执行完之后，另一个线程才能进来执行第2步。

![image-20210719201053417](https://gitee.com/jiao_qianjin/zhishiku/raw/master/img/20210719201053.png) 

在单机部署下，多个线程之间只能串行化执行，这时数据不会有问题。但是随着业务越来越复杂，并发量飙升。我们需要增加更多的机器以适应业务的需求。

![image-20210718211528073](https://gitee.com/jiao_qianjin/zhishiku/raw/master/img/20210718211528.png)

这时候虽然加了锁，但是锁已经失效了，因为两台机器上的锁不是同一把锁，两把锁在不同的JVM里。

这时候就需要引入分布式锁，目前主流的分布式锁的实现方案有三种

- 基于ZooKeeper的分布式锁
- 基于Redis的分布式锁
- 基于数据库实现

分布式锁的思路是：在整个系统提供一个**全局、唯一**的获取锁的“东西”，然后每个系统在需要加锁时，都去问这个“东西”拿到一把锁，这样不同的系统拿到的就可以认为是同一把锁。

![image-20210718212449282](https://gitee.com/jiao_qianjin/zhishiku/raw/master/img/20210718212449.png)

## 2. 公平锁和可重入锁

### 2.1 公平锁

公平锁：每个线程抢占锁的顺序为先后调用lock方法的顺序依次获取锁，类似于排队吃饭。

![image-20210714210650306](https://gitee.com/jiao_qianjin/zhishiku/raw/master/img/20210714210651.png)

### 2.2 可重入锁

可重入锁：某个线程已经获得某个锁，再未释放锁之前，可以再次获取锁而不会出现死锁

一个方法里，外层方法占用了锁，但是里面还有方法要获得锁，如果不是重入锁，程序无法继续运行，陷入死锁，是重入锁就继续执行。

![image-20210714210808840](https://gitee.com/jiao_qianjin/zhishiku/raw/master/img/20210714210808.png)

最经典的分布式锁是可重入的公平锁。

## 3. Zookeeper分布式锁实现原理

**分布式锁的条件**

> 1、在分布式系统的环境下，一个方法在同一时间，只能被一个机器下的一个线程使用。
>
> 2、这把锁在一段有限的时间之后，一定会被释放（正常释放或异常释放）
>
> 3、锁被释放别的竞争者一定要知道

**ZooKeeper的节点类型？**

**ZooKeeper的临时有序节点，适合实现分布式锁**

### 3.1. 有序节点

在一个节点下创建临时有序节点类型，新的子节点次序编号会在上一个子节点的次序编号上+1

例如我们可以创建子节点“/locks/seq-”并且指明有序，那么zookeeper在生成子节点时会根据当前的子节点数量自动添加整数序号，也就是说如果是第一个创建的子节点，那么生成的子节点为/locks/seq-0000000000，下一个节点则为/locks/seq-0000000001，依次类推。

编号最小的那个节点，可以获得锁。所以，每个线程在尝试占用锁之前，首先判断自己是排号是不是当前最小，如果是，则获取锁。

### 3.2.  临时节点

客户端可以建立一个临时节点，在会话结束或者会话超时后，zookeeper会自动删除该节点。

### 3.3.  事件监听

在读取数据时，我们可以同时对节点设置事件监听，当节点数据或结构变化时，zookeeper会通知客户端。当前zookeeper有如下四种事件：1）节点创建；2）节点删除；3）节点数据修改；4）子节点变更。

节点监听机制，可以保障占有锁的传递有序而且高效。

每一个等通知的Znode节点，只需要监听（linsten）或者监视（watch）排号在自己前面那个，而且紧挨在自己前面的那个节点，就能收到其删除事件了。
只要上一个节点被删除了，就进行再一次判断，看看自己是不是序号最小的那个节点，如果是，自己就获得锁。

![image-20210708145511082](https://gitee.com/jiao_qianjin/zhishiku/raw/master/img/20210715082653.png)

### 3.4.  思考：

1. 客户端A获取到锁之后，宕机了，会不会造成死锁?

2. 客户端A对应子节点为/locks/seq-0000001,客户端B对应节点/locks/seq-0000002，客户端B获取子节点列表的时候发现自己的节点次序不是最小的，但是设置完监听器前，客户端A释放了锁，删除了节点/locks/seq-0000001，客户端b设置的监听器岂不是丢失了这个事件从而导致永远等待了？

## 4. 具体流程

![image-20210715100549956](https://gitee.com/jiao_qianjin/zhishiku/raw/master/img/20210715100550.png)

> 1. 客户端A想要获取资源，发起一个加锁请求。在/locks节点下创建一个临时节点_c_6 ... e6c-lock-000000001，
> 2. 然后获取/locks下所有的子节点，按照顺序排列，然后客户端A进行一个判断，判断自己是否为第一个节点，因为客户端A是第一个创建节点的，所以可以拿到锁。
> 3. 这是客户端B想要获取资源，也会发起一个加锁请求，同样的，会在/locks节点下创建一个临时节点，这个节点的次序会在上一个节点的次序上递增（_c_6 ... e6c-lock-000000002）
> 4. 重复第二步操作，这时候客户端B进行判断，此时客户端A还没有释放锁，节点还没有被删除，因此客户端B的节点不是最小节点。不能获取锁
> 5. 我们只需要监听上一个节点的变化，等待上一节点被删除
> 6. 客户端A完成业务流程后，释放锁，临时节点_c_6 ... e6c-lock-000000001被删除，
> 7. 监听器监听到上个节点被删除
> 8. 再次尝试加锁，判断自己是否为第一个节点，是，加锁成功。

可重入锁实现：

在加锁逻辑中添加一个加锁的计数器lockCount，计算重复加锁的次数，如果是同一个线程加锁，计数器+1

释放锁如果是同一线程，计数器-1，如果不是0，返回，如果是0，删除临时节点，释放锁。

## 5. 实现

### 5.1. Java API实现

#### 5.1.1. 代码实现



```java
package com.marchsoft.case2;

import org.apache.zookeeper.*;
import org.apache.zookeeper.data.Stat;

import java.io.IOException;
import java.util.Collections;
import java.util.List;
import java.util.concurrent.CountDownLatch;

/**
 * Description： zookeeper 分布式锁
 *
 * @author jiaoqianjin
 * Date: 2021/7/8 10:10
 **/

public class DistributeLock {
    /**
     * zookeeper server 列表
     */
    private String connectString = "zookeeper1:2181,zookeeper2:2181,zookeeper2:2181";
    /**
     * 超时时间
     */
    private int sessionTimeout = 2000;
    private ZooKeeper zk;
    private String rootNode = "locks";
    private String subNode = "seq-";
    /**
     * 当前 client 等待的子节点
     */
    private String waitPath;
    /**
     * ZooKeeper 连接
     */
    private CountDownLatch connectLatch = new CountDownLatch(1);
    /**
     * ZooKeeper 节点等待
     */
    private CountDownLatch waitLatch = new CountDownLatch(1);
    /**
     * 当前 client 创建的子节点
     */
    private String currentNode;

    /**
     * 功能描述: 和 zk 服务建立连接，并创建根节点
     *
     * @author jiaoqianjin
     * @date 2021/7/8
     */
    public DistributeLock() throws IOException, InterruptedException, KeeperException {
        zk = new ZooKeeper(connectString, sessionTimeout, new Watcher() {
            @Override
            public void process(WatchedEvent event) {
                // 连接建立时, 打开 latch, 唤醒 wait 在该 latch 上的线程
                if (event.getState() == Event.KeeperState.SyncConnected) {
                    connectLatch.countDown();
                }
                // 发生了 waitPath 的删除事件
                if (event.getType() == Event.EventType.NodeDeleted && event.getPath().equals(waitPath)) {
                    waitLatch.countDown();
                }
            }
        });
        // 等待连接建立
        connectLatch.await();
        //获取根节点状态
        Stat stat = zk.exists("/" + rootNode, false);
        //如果根节点不存在，则创建根节点，根节点类型为永久节点
        if (stat == null) {
            System.out.println("根节点不存在");
            zk.create("/" + rootNode, new byte[0], ZooDefs.Ids.OPEN_ACL_UNSAFE, CreateMode.PERSISTENT);
        }
    }

    /**
     * 功能描述: 加锁方法
     *
     * @author jiaoqianjin
     * @date 2021/7/8
     */
    public void zkLock() {
        try {
            //在根节点下创建临时顺序节点，返回值为创建的节点路径
            currentNode = zk.create("/" + rootNode + "/" + subNode, null, ZooDefs.Ids.OPEN_ACL_UNSAFE,
                    CreateMode.EPHEMERAL_SEQUENTIAL);
            // wait 一小会, 让结果更清晰一些
            Thread.sleep(10);
            // 注意, 没有必要监听"/locks"的子节点的变化情况
            List<String> childrenNodes = zk.getChildren("/" + rootNode, false);
            // 列表中只有一个子节点, 那肯定就是 currentNode , 说明client 获得锁
            if (childrenNodes.size() == 1) {
                return;
            } else {
                //对根节点下的所有临时顺序节点进行从小到大排序
                Collections.sort(childrenNodes);
                //当前节点名称
                String thisNode = currentNode.substring(("/" + rootNode + "/").length());
                //获取当前节点的位置
                int index = childrenNodes.indexOf(thisNode);
                if (index == -1) {
                    System.out.println("数据异常");
                } else if (index == 0) {
                    // index == 0, 说明 thisNode 在列表中最小, 当前client 获得锁
                    return;
                } else {
                    // 获得排名比 currentNode 前 1 位的节点
                    this.waitPath = "/" + rootNode + "/" + childrenNodes.get(index - 1);
                    // 在 waitPath 上注册监听器, 当 waitPath 被删除时,zookeeper 会回调监听器的 process 方法
                    zk.getData(waitPath, true, new Stat());
                    //进入等待锁状态
                    waitLatch.await();
                    return;
                }
            }
        } catch (KeeperException e) {
            e.printStackTrace();
        } catch (InterruptedException e) {
            e.printStackTrace();
        }
    }

    /**
     * 功能描述: 解锁方法
     *
     * @author jiaoqianjin
     * @date 2021/7/8
     */
    public void zkUnlock() {
        try {
            zk.delete(this.currentNode, -1);
        } catch (Exception e) {
            e.printStackTrace();
        }
    }
}
```



#### 5.1.2. 测试



```java
package com.marchsoft.case2;

import org.apache.zookeeper.KeeperException;

import java.io.IOException;

/**
 * Description：
 *
 * @author jiaoqianjin
 * Date: 2021/7/8 10:32
 **/

public class DistributeLockTest {
    public static void main(String[] args) throws InterruptedException, IOException, KeeperException {
        // 创建分布式锁 1
        final DistributeLock lock1 = new DistributeLock();
        // 创建分布式锁 2
        final DistributeLock lock2 = new DistributeLock();
        new Thread(new Runnable() {
            @Override
            public void run() {
                // 获取锁对象
                try {
                    lock1.zkLock();
                    System.out.println("线程 1 获取锁");
                    Thread.sleep(5 * 1000);
                    lock1.zkUnlock();
                    System.out.println("线程 1 释放锁");
                } catch (Exception e) {
                    e.printStackTrace();
                }
            }
        }).start();

        new Thread(new Runnable() {
            @Override
            public void run() {
                // 获取锁对象
                try {
                    lock2.zkLock();
                    System.out.println("线程 2 获取锁");
                    Thread.sleep(5 * 1000);
                    lock2.zkUnlock();
                    System.out.println("线程 2 释放锁");
                } catch (Exception e) {
                    e.printStackTrace();
                }
            }
        }).start();
    }
}
```



#### 5.1.3. 结果



![image](https://gitee.com/jiao_qianjin/zhishiku/raw/master/img/20210725111713.png)

### 5.2. Curator 框架实现分布式锁案例

#### 5.2.1. 原生的 Java API 开发存在的问题

（1）会话连接是异步的，需要自己去处理。比如使用 CountDownLatch

（2）Watch 需要重复注册，不然就不能生效

（3）开发的复杂性还是比较高的

（4）不支持多节点删除和创建。需要自己去递归



#### 5.2.2. 文档

Curator 是一个专门解决分布式锁的框架，解决了原生 JavaAPI 开发分布式遇到的问题。

官方文档：https://curator.apache.org/index.html

#### 5.2.3. Curator 案例实操

##### 1. 添加依赖



```xml
<dependency>
 <groupId>org.apache.curator</groupId>
 <artifactId>curator-framework</artifactId>
 <version>4.3.0</version>
</dependency>
<dependency>
 <groupId>org.apache.curator</groupId>
 <artifactId>curator-recipes</artifactId>
 <version>4.3.0</version>
</dependency>
<dependency>
 <groupId>org.apache.curator</groupId>
 <artifactId>curator-client</artifactId>
 <version>4.3.0</version>
</dependency>
```



##### 2. 代码实现



```java
package com.marchsoft.case3;

import org.apache.curator.RetryPolicy;
import org.apache.curator.framework.CuratorFramework;
import org.apache.curator.framework.CuratorFrameworkFactory;
import org.apache.curator.framework.recipes.locks.InterProcessLock;
import org.apache.curator.framework.recipes.locks.InterProcessMutex;
import org.apache.curator.retry.ExponentialBackoffRetry;

/**
 * Description：
 *
 * @author jiaoqianjin
 * Date: 2021/7/8 10:38
 **/

public class CuratorLockTest {
    private String rootNode = "/locks";
    /**
     * zookeeper server 列表
     */
    private String connectString =
            "zookeeper:2181";
    /**
     * connection 超时时间
     */
    private int connectionTimeout = 2000;
    /**
     * session 超时时间
     */
    private int sessionTimeout = 2000;

    public static void main(String[] args) {
        new CuratorLockTest().test();
    }

    /**
     * 测试
     */
    private void test() {
        // 创建分布式锁 1
        final InterProcessLock lock1 = new InterProcessMutex(getCuratorFramework(), rootNode);
        // 创建分布式锁 2
        final InterProcessLock lock2 = new InterProcessMutex(getCuratorFramework(), rootNode);
        new Thread(new Runnable() {
            @Override
            public void run() {
                // 获取锁对象
                try {
                    lock1.acquire();
                    System.out.println("线程 1 获取锁");
                    // 测试锁重入
                    lock1.acquire();
                    System.out.println("线程 1 再次获取锁");
                    Thread.sleep(5 * 1000);
                    lock1.release();
                    System.out.println("线程 1 释放锁");
                    lock1.release();
                    System.out.println("线程 1 再次释放锁");
                } catch (Exception e) {
                    e.printStackTrace();
                }
            }
        }).start();
        new Thread(new Runnable() {
            @Override
            public void run() {
                // 获取锁对象
                try {
                    lock2.acquire();
                    System.out.println("线程 2 获取锁");
                    // 测试锁重入
                    lock2.acquire();
                    System.out.println("线程 2 再次获取锁");
                    Thread.sleep(5 * 1000);
                    lock2.release();
                    System.out.println("线程 2 释放锁");
                    lock2.release();
                    System.out.println("线程 2 再次释放锁");
                } catch (Exception e) {
                    e.printStackTrace();
                }
            }
        }).start();
    }

    /**
     * 分布式锁初始化
     */
    public CuratorFramework getCuratorFramework() {
        //重试策略，初试时间 3 秒，重试 3 次
        RetryPolicy policy = new ExponentialBackoffRetry(3000, 3);
        //通过工厂创建 Curator
        CuratorFramework client = CuratorFrameworkFactory.builder()
                .connectString(connectString)
                .connectionTimeoutMs(connectionTimeout)
                .sessionTimeoutMs(sessionTimeout)
                .retryPolicy(policy).build();
        //开启连接
        client.start();
        System.out.println("zookeeper 初始化完成...");
        return client;
    }
}
```

##### 3. 运行结果

![image](https://gitee.com/jiao_qianjin/zhishiku/raw/master/img/20210725111651.png) 

## 6. 总结

### 6.1. 优点

1. 使用简单，可以解决不可重入问题
2. 临时有序节点，避免了多个客户端被唤醒等待锁，当锁释放时只有下一个节点的客户端被唤醒
3. 获取锁的客户端在出现故障的时候锁也会被释放，不会出现死锁。

### 6.2. 缺点

1. 性能低，在加锁和释放锁的时候需要创建和删除节点，创建和删除都需要Leader服务器执行，并同步到所有的Follower机器



**待探究对比： Redis实现分布式锁、数据库实现分布式锁。**



## 7. 分享产生问题

### 1. 网络问题导致锁释放问题

**问题描述：**客户端1拿到锁之后，因为网络问题导致会话超时以至于节点被删除，锁被释放。客户端2检测到上一个节点被释放之后，获取到锁。这时候客户端1网络恢复之后，因为锁被释放，业务无法执行，这时候zookeeper有没有机制来解决这种问题？

![image-20210728091122390](https://gitee.com/jiao_qianjin/zhishiku/raw/master/img/20210728091130.png)

**解决方案：**

> 如上图所示，客户端1发生GC停顿的时候，zookeeper检测不到心跳，也是有可能出现多个客户端同时操作共享资源的情形。当然，你可以说，我们可以通过JVM调优，避免GC停顿出现。但是注意了，我们所做的一切，只能尽可能避免多个客户端操作共享资源，无法完全消除。



#### 2. zookeeper有序节点数值问题

**问题描述：**zookeeper有序节点会根据当前的子节点数量自动添加整数序号，整数达到最大值会怎么处理

**解决方案：**

>



