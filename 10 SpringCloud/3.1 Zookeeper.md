# Zookeeper

 [【尚硅谷】2021最新版Zookeeper 3.5.7版本教程](https://www.bilibili.com/video/BV1to4y1C7gw?p=1)

## 1. 概述

​	Zookeeper 是一个开源的分布式的，为分布式框架提供协调服务的 Apache 项目。

## 2. Zookeeper 工作机制

> Zookeeper从设计模式角度来理解：是一个基于观察者模式设计的分布式服务管理框架，它负责 存储和管理大家都关心的数据，然 后接受观察者的 注 册，一旦这些数据的状态发生变化，Zookeeper 就 将负责通知已经在Zookeeper上注册的那些观察 者做出相应的反应。

## 3. 特点

1）Zookeeper：一个领导者（Leader），多个跟随者（Follower）组成的集群。 

2）集群中只要有半数以上节点存活，Zookeeper集群就能正常服务。所 以Zookeeper适合安装奇数台服务器。 

3）全局数据一致：每个Server保存一份相同的数据副本，Client无论连接到哪个Server，数据都是一致的。 

4）更新请求顺序执行，来自同一个Client的更新请求按其发送顺序依次执行。 

5）数据更新原子性，一次数据更新要么成功，要么失败。

6）实时性，在一定时间范围内，Client能读到最新数据。

## 4. 应用场景

​		提供的服务包括：统一命名服务、统一配置管理、统一集群管理、服务器节点动态上下 线、软负载均衡等。

### 1.  统一命名服务

​		在分布式环境下，经常需要对应用/服 务进行统一命名，便于识别。 

​		例如：IP不容易记住，而域名容易记住。

### 2. 统一配置管理

​		1）分布式环境下，配置文件同步非常常见。

​			（1）一般要求一个集群中，所有节点的配置信息是 一致的，比如 Kafka 集群。

​			（2）对配置文件修改后，希望能够快速同步到各个 节点上。

​		2）配置管理可交由ZooKeeper实现。

​			（1）可将配置信息写入ZooKeeper上的一个Znode。

​			（2）各个客户端服务器监听这个Znode。 

​			（3）一 旦Znode中的数据被修改，ZooKeeper将通知 各个客户端服务器。

![image-20210708142019427](https://gitee.com/jiao_qianjin/zhishiku/raw/master/img/20210708142027.png) 

### 3. 统一集群管理

​	1）分布式环境中，实时掌握每个节点的状态是必要的。 

​		（1）可根据节点实时状态做出一些调整。

​	2）ZooKeeper可以实现实时监控节点状态变化 

​		（1）可将节点信息写入ZooKeeper上的一个ZNode。 

​		（2）监听这个ZNode可获取它的实时状态变化。

### 4. 服务器动态上下线

​		客户端能实时洞察到服务 器上下线的变化

![image-20210708142239752](https://gitee.com/jiao_qianjin/zhishiku/raw/master/img/20210714154700.png)

### 5. 软负载均衡

​		在Zookeeper中记录每台服务器的访问数，让访问数最少的服务器去处理最新的客户端请求

![image-20210708142326782](https://gitee.com/jiao_qianjin/zhishiku/raw/master/img/20210708142326.png) 

## 5. 配置参数解读

​	Zookeeper中的配置文件zoo.cfg中参数含义解读如下：

​		1．tickTime =2000：通信心跳数，Zookeeper服务器与客户端心跳时间，单位毫秒

​			Zookeeper使用的基本时间，服务器之间或客户端与服务器之间维持心跳的时间间隔，也就是每个tickTime时间就会发送一个心跳，时间单位为毫秒。

​			它用于心跳机制，并且设置最小的session超时时间为两倍心跳时间。(session的最小超时时间是2*tickTime)

​		2．initLimit =10：LF初始通信时限

​			集群中的Follower跟随者服务器与Leader领导者服务器之间初始连接时能容忍的最多心跳数（tickTime的数量），用它来限定集群中的Zookeeper服务器连			接到Leader的时限。

​		3．syncLimit =5：LF同步通信时限

​			集群中Leader与Follower之间的最大响应时间单位，假如响应超过syncLimit * tickTime，Leader认为Follwer死掉，从服务器列表中删除Follwer。

​		4．dataDir：数据文件目录+数据持久化路径

​			主要用于保存Zookeeper中的数据。

​		5．clientPort =2181：客户端连接端口

​			监听客户端连接的端口。

## 6. 选举机制

### 1. 第一次启动

![image-20210708142902940](https://gitee.com/jiao_qianjin/zhishiku/raw/master/img/20210714154629.png)

（1）服务器1启 动，发起一次选举。服务器1投自己一票。此时服务器1票数一票，不够半数以上（3票），选举无法完成，服务器1状态保持为 LOOKING；

 （2）服务器2启动，再发起一次选举。服务器1和2分别投自己一票并交换选票信息：此时服务器1发现服务器2的myid比自己目前投票推举的（服务器1） 大，更改选票为推举服务器2。此时服务器1票数0票，服务器2票数2票，没有半数以上结果，选举无法完成，服务器1，2状态保持LOOKING 

（3）服务器3启动，发起一次选举。此时服务器1和2都会更改选票为服务器3。此次投票结果：服务器1为0票，服务器2为0票，服务器3为3票。此时服 务器3的票数已经超过半数，服务器3当选Leader。服务器1，2更改状态为FOLLOWING，服务器3更改状态为LEADING； LOOKING LOOKING 

（4）服务器4启动，发起一次选举。此时服务器1，2，3已经不是LOOKING状态，不会更改选票信息。交换选票信息结果：服务器3为3票，服务器4为 1票。此时服务器4服从多数，更改选票信息为服务器3，并更改状态为FOLLOWING； 

（5）服务器5启动，同4一样状态为FOLLOWING。

**选举规则：投票过半数时，服务器 id 大的胜出**

### 2. 非第一次启动

![image-20210708143616394](https://gitee.com/jiao_qianjin/zhishiku/raw/master/img/20210714154640.png)

（1）当ZooKeeper集群中的一台服务器出现以下两种情况之一时，就会开始进入Leader选举：

​		 • 服务器初始化启动。

​		 • 服务器运行期间无法和Leader保持连接。 

（2）而当一台机器进入Leader选举流程时，当前集群也可能会处于以下两种状态：

​		 • 集群中本来就已经存在一个Leader。 对于第一种已经存在Leader的情况，机器试图去选举Leader时，会被告知当前服务器的Leader信息，对于该机器来说，仅仅需要和Leader机器建立连 接，并进行状态同步即可。 

​		**• 集群中确实不存在Leader。**

​			 假设ZooKeeper由5台服务器组成，SID分别为1、2、3、4、5，ZXID分别为8、8、8、7、7，并且此时SID为3的服务器是Leader。某一时刻， 3和5服务器出现故障，因此开始进行Leader选举。 （EPOCH，ZXID，SID ）

 SID为1、2、4的机器投票情况： 

| （EPOCH，ZXID，SID ） | （EPOCH，ZXID，SID ） | （EPOCH，ZXID，SID ） |
| --------------------- | --------------------- | --------------------- |
| （1，8，1）           | （1，8，2）           | （1，7，4）           |

 **选举Leader规则：** 

​	**①EPOCH大的直接胜出** 

​	**②EPOCH相同，事务id大的胜出**

​	**③事务id相同，服务器id大的胜出**

## 7. 节点类型

持久（Persistent）：客户端和服务器端断开连接后，创建的节点不删除

短暂（Ephemeral）：客户端和服务器端断开连接后，创建的节点自己删除

（1）持久化目录节点 

​		客户端与Zookeeper断开连接后，该节点依旧存在

（2）持久化顺序编号目录节点 

​		客户端与Zookeeper断开连接后，该节点依旧存 在，只是Zookeeper给该节点名称进行顺序编号

（3）临时目录节点 

​		客户端与Zookeeper断开连接后，该节点被删除

（4）临时顺序编号目录节点 

​		客户端与 Zookeeper 断开连接后 ， 该 节 点 被 删 除 ， 只 是 Zookeeper给该节点名称进行顺序编号。

## 8. 监听器原理

​		客户端注册监听它关心的目录节点，当目录节点发生变化（数据改变、节点删除、子目 录节点增加删除）时，ZooKeeper 会通知客户端。监听机制保证 ZooKeeper 保存的任何的数 据的任何改变都能快速的响应到监听了该节点的应用程序。

1、监听原理详解

​	1）首先要有一个main()线程 

​	2）在main线程中创建Zookeeper客户端，这时就会创建两个线 程，一个负责网络连接通信（connet），一个负责监听（listener）。

​	3）通过connect线程将注册的监听事件发送给Zookeeper。 

​	4）在Zookeeper的注册监听器列表中将注册的监听事件添加到列表中。 

​	5）Zookeeper监听到有数据或路径变化，就会将这个消息发送给listener线程。

​	6）listener线程内部调用了process()方法。

2、常见的监听

​	1）监听节点数据的变化 

```sh
get path [watch] 
```

​	2）监听子节点增减的变化

```sh
 ls path [watch]
```

![image-20210708144314419](https://gitee.com/jiao_qianjin/zhishiku/raw/master/img/20210708144314.png)

## 9. 客户端向服务端写数据流程

### 1. 写流程之写入请求直接发送给Leader节点

![image-20210708144437218](https://gitee.com/jiao_qianjin/zhishiku/raw/master/img/20210708144437.png) 

### 3. 写流程之写入请求发送给follower节点

![image-20210708144954891](https://gitee.com/jiao_qianjin/zhishiku/raw/master/img/20210708144954.png)

## 10. 分布式锁

### 1. Java API 实现

#### 1. 原理

> 什么叫做分布式锁呢？ 比如说"进程 1"在使用该资源的时候，会先去获得锁，"进程 1"获得锁以后会对该资源保持独占，这样其他进程就无法访问该资源，"进程 1"用完该资源以后就将锁释放掉，让其 他进程来获得锁，那么通过这个锁机制，我们就能保证了分布式系统中多个进程能够有序的 访问该临界资源。那么我们把这个分布式环境下的这个锁叫作分布式锁。

![image-20210708145511082](https://gitee.com/jiao_qianjin/zhishiku/raw/master/img/20210708145511.png)

#### 2. 代码实现

```java
package com.marchsoft.case2;

import org.apache.zookeeper.*;
import org.apache.zookeeper.data.Stat;

import java.io.IOException;
import java.util.Collections;
import java.util.List;
import java.util.concurrent.CountDownLatch;

/**
 * Description： zookeeper 分布式锁
 *
 * @author jiaoqianjin
 * Date: 2021/7/8 10:10
 **/

public class DistributeLock {
    /**
     * zookeeper server 列表
     */
    private String connectString = "zookeeper1:2181,zookeeper2:2181,zookeeper2:2181";
    /**
     * 超时时间
     */
    private int sessionTimeout = 2000;
    private ZooKeeper zk;
    private String rootNode = "locks";
    private String subNode = "seq-";
    /**
     * 当前 client 等待的子节点
     */
    private String waitPath;
    /**
     * ZooKeeper 连接
     */
    private CountDownLatch connectLatch = new CountDownLatch(1);
    /**
     * ZooKeeper 节点等待
     */
    private CountDownLatch waitLatch = new CountDownLatch(1);
    /**
     * 当前 client 创建的子节点
     */
    private String currentNode;

    /**
     * 功能描述: 和 zk 服务建立连接，并创建根节点
     *
     * @author jiaoqianjin
     * @date 2021/7/8
     */
    public DistributeLock() throws IOException, InterruptedException, KeeperException {
        zk = new ZooKeeper(connectString, sessionTimeout, new Watcher() {
            @Override
            public void process(WatchedEvent event) {
                // 连接建立时, 打开 latch, 唤醒 wait 在该 latch 上的线程
                if (event.getState() == Event.KeeperState.SyncConnected) {
                    connectLatch.countDown();
                }
                // 发生了 waitPath 的删除事件
                if (event.getType() == Event.EventType.NodeDeleted && event.getPath().equals(waitPath)) {
                    waitLatch.countDown();
                }
            }
        });
        // 等待连接建立
        connectLatch.await();
        //获取根节点状态
        Stat stat = zk.exists("/" + rootNode, false);
        //如果根节点不存在，则创建根节点，根节点类型为永久节点
        if (stat == null) {
            System.out.println("根节点不存在");
            zk.create("/" + rootNode, new byte[0], ZooDefs.Ids.OPEN_ACL_UNSAFE, CreateMode.PERSISTENT);
        }
    }

    /**
     * 功能描述: 加锁方法
     *
     * @author jiaoqianjin
     * @date 2021/7/8
     */
    public void zkLock() {
        try {
            //在根节点下创建临时顺序节点，返回值为创建的节点路径
            currentNode = zk.create("/" + rootNode + "/" + subNode, null, ZooDefs.Ids.OPEN_ACL_UNSAFE,
                    CreateMode.EPHEMERAL_SEQUENTIAL);
            // wait 一小会, 让结果更清晰一些
            Thread.sleep(10);
            // 注意, 没有必要监听"/locks"的子节点的变化情况
            List<String> childrenNodes = zk.getChildren("/" + rootNode, false);
            // 列表中只有一个子节点, 那肯定就是 currentNode , 说明client 获得锁
            if (childrenNodes.size() == 1) {
                return;
            } else {
                //对根节点下的所有临时顺序节点进行从小到大排序
                Collections.sort(childrenNodes);
                //当前节点名称
                String thisNode = currentNode.substring(("/" + rootNode + "/").length());
                //获取当前节点的位置
                int index = childrenNodes.indexOf(thisNode);
                if (index == -1) {
                    System.out.println("数据异常");
                } else if (index == 0) {
                    // index == 0, 说明 thisNode 在列表中最小, 当前client 获得锁
                    return;
                } else {
                    // 获得排名比 currentNode 前 1 位的节点
                    this.waitPath = "/" + rootNode + "/" + childrenNodes.get(index - 1);
                    // 在 waitPath 上注册监听器, 当 waitPath 被删除时,zookeeper 会回调监听器的 process 方法
                    zk.getData(waitPath, true, new Stat());
                    //进入等待锁状态
                    waitLatch.await();
                    return;
                }
            }
        } catch (KeeperException e) {
            e.printStackTrace();
        } catch (InterruptedException e) {
            e.printStackTrace();
        }
    }

    /**
     * 功能描述: 解锁方法
     *
     * @author jiaoqianjin
     * @date 2021/7/8
     */
    public void zkUnlock() {
        try {
            zk.delete(this.currentNode, -1);
        } catch (Exception e) {
            e.printStackTrace();
        }
    }
}
```

#### 3. 测试

```java
package com.marchsoft.case2;

import org.apache.zookeeper.KeeperException;

import java.io.IOException;

/**
 * Description：
 *
 * @author jiaoqianjin
 * Date: 2021/7/8 10:32
 **/

public class DistributeLockTest {
    public static void main(String[] args) throws InterruptedException, IOException, KeeperException {
        // 创建分布式锁 1
        final DistributeLock lock1 = new DistributeLock();
        // 创建分布式锁 2
        final DistributeLock lock2 = new DistributeLock();
        new Thread(new Runnable() {
            @Override
            public void run() {
                // 获取锁对象
                try {
                    lock1.zkLock();
                    System.out.println("线程 1 获取锁");
                    Thread.sleep(5 * 1000);
                    lock1.zkUnlock();
                    System.out.println("线程 1 释放锁");
                } catch (Exception e) {
                    e.printStackTrace();
                }
            }
        }).start();

        new Thread(new Runnable() {
            @Override
            public void run() {
                // 获取锁对象
                try {
                    lock2.zkLock();
                    System.out.println("线程 2 获取锁");
                    Thread.sleep(5 * 1000);
                    lock2.zkUnlock();
                    System.out.println("线程 2 释放锁");
                } catch (Exception e) {
                    e.printStackTrace();
                }
            }
        }).start();
    }
}

```

#### 4. 结果

![image-20210708145754376](https://gitee.com/jiao_qianjin/zhishiku/raw/master/img/20210708145754.png) 

### 2. Curator 框架实现分布式锁案例

#### 1）原生的 Java API 开发存在的问题 

（1）会话连接是异步的，需要自己去处理。比如使用 CountDownLatch 

（2）Watch 需要重复注册，不然就不能生效 

（3）开发的复杂性还是比较高的 

（4）不支持多节点删除和创建。需要自己去递归 

#### 2）文档

Curator 是一个专门解决分布式锁的框架，解决了原生 JavaAPI 开发分布式遇到的问题。

 	官方文档：https://curator.apache.org/index.html 

#### 3）Curator 案例实操

##### 1. 添加依赖

```xml
<dependency>
 <groupId>org.apache.curator</groupId>
 <artifactId>curator-framework</artifactId>
 <version>4.3.0</version>
</dependency>
<dependency>
 <groupId>org.apache.curator</groupId>
 <artifactId>curator-recipes</artifactId>
 <version>4.3.0</version>
</dependency>
<dependency>
 <groupId>org.apache.curator</groupId>
 <artifactId>curator-client</artifactId>
 <version>4.3.0</version>
</dependency>
```

##### 2. 代码实现

```java
package com.marchsoft.case3;

import org.apache.curator.RetryPolicy;
import org.apache.curator.framework.CuratorFramework;
import org.apache.curator.framework.CuratorFrameworkFactory;
import org.apache.curator.framework.recipes.locks.InterProcessLock;
import org.apache.curator.framework.recipes.locks.InterProcessMutex;
import org.apache.curator.retry.ExponentialBackoffRetry;

/**
 * Description：
 *
 * @author jiaoqianjin
 * Date: 2021/7/8 10:38
 **/

public class CuratorLockTest {
    private String rootNode = "/locks";
    /**
     * zookeeper server 列表
     */
    private String connectString =
            "zookeeper:2181";
    /**
     * connection 超时时间
     */
    private int connectionTimeout = 2000;
    /**
     * session 超时时间
     */
    private int sessionTimeout = 2000;

    public static void main(String[] args) {
        new CuratorLockTest().test();
    }

    /**
     * 测试
     */
    private void test() {
        // 创建分布式锁 1
        final InterProcessLock lock1 = new InterProcessMutex(getCuratorFramework(), rootNode);
        // 创建分布式锁 2
        final InterProcessLock lock2 = new InterProcessMutex(getCuratorFramework(), rootNode);
        new Thread(new Runnable() {
            @Override
            public void run() {
                // 获取锁对象
                try {
                    lock1.acquire();
                    System.out.println("线程 1 获取锁");
                    // 测试锁重入
                    lock1.acquire();
                    System.out.println("线程 1 再次获取锁");
                    Thread.sleep(5 * 1000);
                    lock1.release();
                    System.out.println("线程 1 释放锁");
                    lock1.release();
                    System.out.println("线程 1 再次释放锁");
                } catch (Exception e) {
                    e.printStackTrace();
                }
            }
        }).start();
        new Thread(new Runnable() {
            @Override
            public void run() {
                // 获取锁对象
                try {
                    lock2.acquire();
                    System.out.println("线程 2 获取锁");
                    // 测试锁重入
                    lock2.acquire();
                    System.out.println("线程 2 再次获取锁");
                    Thread.sleep(5 * 1000);
                    lock2.release();
                    System.out.println("线程 2 释放锁");
                    lock2.release();
                    System.out.println("线程 2 再次释放锁");
                } catch (Exception e) {
                    e.printStackTrace();
                }
            }
        }).start();
    }

    /**
     * 分布式锁初始化
     */
    public CuratorFramework getCuratorFramework() {
        //重试策略，初试时间 3 秒，重试 3 次
        RetryPolicy policy = new ExponentialBackoffRetry(3000, 3);
        //通过工厂创建 Curator
        CuratorFramework client = CuratorFrameworkFactory.builder()
                .connectString(connectString)
                .connectionTimeoutMs(connectionTimeout)
                .sessionTimeoutMs(sessionTimeout)
                .retryPolicy(policy).build();
        //开启连接
        client.start();
        System.out.println("zookeeper 初始化完成...");
        return client;
    }
}

```

##### 3. 运行结果

![image-20210708150810517](https://gitee.com/jiao_qianjin/zhishiku/raw/master/img/20210708150810.png) 

## 11. 面试真题

### 1 选举机制 

半数机制，超过半数的投票通过，即通过。

​	1）第一次启动选举规则： 

​		投票过半数时，服务器 id 大的胜出 

​	2）第二次启动选举规则： 

​		①EPOCH 大的直接胜出

​		 ②EPOCH 相同，事务 id 大的胜出

​		 ③事务 id 相同，服务器 id 大的胜出 

### 2 生产集群安装多少 zk 合适？ 

安装奇数台。 

生产经验： 

⚫ 10 台服务器：3 台 zk； 

⚫ 20 台服务器：5 台 zk；

⚫ 100 台服务器：11 台 zk； 

⚫ 200 台服务器：11 台 

zk 服务器台数多：好处，提高可靠性；坏处：提高通信延时 

### 3 常用命令 

| 命令基本语法 | 功能描述                                                     |
| ------------ | ------------------------------------------------------------ |
| help         | 显示所有操作命令                                             |
| ls path      | 使用 ls 命令来查看当前 znode 的子节点 [可监听] <br />-w 监听子节点变化 <br />-s 附加次级信息 |
| create       | 普通创建 <br />-s 含有序列 <br />-e 临时（重启或者超时消失） |
| get path     | 获得节点的值 [可监听] <br />-w 监听节点内容变化 <br />-s 附加次级信息 |
| set          | 设置节点的具体值                                             |
| stat         | 查看节点状态                                                 |
| delete       | 删除节点                                                     |
| deleteall    | 递归删除节点                                                 |

## 12. 知识补充

### 1. 会话（Session）

> Session 是指客户端会话，在了解客户端会话之前，我们先来了解下客户端连接。在 ZooKeeper 中，一个客户端连接是指客户端和 ZooKeeper 服务器之间的TCP长连接。
>
> ZooKeeper 对外的服务端口默认是2181，客户端启动时，首先会与服务器建立一个TCP连接，从第一次连接建立开始，客户端会话的生命周期也开始了，通过这个连接，客户端能够通过心跳检测和服务器保持有效的会话，也能够向 ZooKeeper 服务器发送请求并接受响应，同时还能通过该连接接收来自服务器的 Watch 事件通知。
>
> Session 的 SessionTimeout 值用来设置一个客户端会话的超时时间。当由于服务器压力太大、网络故障或是客户端主动断开连接等各种原因导致客户端连接断开时，只要在 SessionTimeout 规定的时间内能够重新连接上集群中任意一台服务器，那么之前创建的会话仍然有效。

### 2. 心跳监测

> 机器间的心跳检测机制是指在分布式环境中，不同机器（或进程）之间需要检测到彼此是否在正常运行，例如A机器需要知道B机器是否正常运行。在传统的开发中，我们通常是通过主机直接是否可以相互PING通来判断，更复杂一点的话，则会通过在机器之间建立长连接，通过TCP连接固有的心跳检测机制来实现上层机器的心跳检测，这些都是非常常见的心跳检测方法。
>
> 下面来看看如何使用ZK来实现分布式机器（进程）间的心跳检测。
>
> 基于ZK的临时节点的特性，可以让不同的进程都在ZK的一个指定节点下创建临时子节点，不同的进程直接可以根据这个临时子节点来判断对应的进程是否存活。通过这种方式，检测和被检测系统直接并不需要直接相关联，而是通过ZK上的某个节点进行关联，大大减少了系统耦合。

### 3. ZAB协议


　　ZAB 协议全称：Zookeeper Atomic Broadcast（Zookeeper 原子广播协议）。
　　ZAB 协议作用：解决分布式数据管理一致性。
　　ZAB 协议定义：ZAB 协议是为分布式协调服务 Zookeeper 专门设计的一种支持 **崩溃恢复 和 消息广播** 协议。
　　基于该协议，Zookeeper 实现了一种 主备模式 的系统架构来保持集群中各个副本之间数据一致性。

#### 消息广播

　　zookeeper集群采用主从（leader-follower）模式保证服务高可用。leader节点可读可写，follower节点只读，这种模式就需要保证leader节点和follower节点的数据一致性。对于客户端发送的写请求，全部由 Leader 接收，Leader 将请求封装成一个事务 Proposal，将其发送给所有 Follwer ，然后，根据所有 Follwer 的反馈，如果**超过半数成功响应**，则执行 commit 操作（先提交自己，再发送 commit 给所有 Follwer）。

　　注：上述中有一个概念：两阶段提交过程（分布式系统中数据一致性经常会涉及到的方案）。**follower节点是可以处理写请求的**，会转发给leader节点。leader节点通过消息广播（二阶段提交）同步写操作到follower节点，保证数据一致性。

　　zookeeper中每个事务都对应一个ZXID（全局的、唯一的、顺序的）。ZXID 是一个 64 位的数字，其中低 32 位可以看作是一个简单的递增的计数器，针对客户端的每一个事务请求，Leader 都会产生一个新的事务 Proposal 并对该计数器进行 + 1 操作。而高 32 位则代表了 Leader 服务器上取出本地日志中最大事务 Proposal 的 ZXID，并从该 ZXID 中解析出对应的 epoch 值，然后再对这个值加一。

#### 崩溃恢复

　　即如果在消息广播的过程中，leader死掉了，如何保证数据的一致性问题。

　　假设两种异常情况：
　　1、一个事务在 Leader 上提交了，并且过半的 Folower 都响应 Ack 了，但是 Leader 在 Commit 消息发出之前挂了。
　　2、假设一个事务在 Leader 提出之后，Leader 挂了。

　　考虑到上述两种异常情况，Zab 协议崩溃恢复要求满足以下两个要求：
　　1）确保已经被 Leader 提交的 Proposal 必须最终被所有的 Follower 服务器提交。
　　2）确保丢弃已经被 Leader 提出的但是没有被提交的 Proposal。

　　崩溃恢复主要包含：leader选举 和 数据恢复。

　　**leader选举**:

　　	1、要求 可用节点数量 > 总节点数量/2 。注意 是 > , 不是 ≥。

　    	2、新选举出来的 Leader 不能包含未提交的 Proposal（新选举的 Leader 必须都是已经提交了 Proposal 的 Follower 服务器节点） 、新选举的 Leader 节点中含有最大的 zxid（可以避免 Leader 服务器检查 Proposal 的提交和丢弃工作。如果zxid相同，选择server_id【zoo.cfg中的myid】最大的。）

　　**数据恢复**：

　　	1、上面讲过了ZXID的高 32 位代表了每代 Leader 的唯一性，低 32 代表了每代 Leader 中事务的唯一性。同时，也能让 Follwer 通过高 32 位识别不同的 Leader。简化了数据恢复流程。

　　	2、基于这样的策略：当 Follower 链接上 Leader 之后，Leader 服务器会根据自己服务器上最后被提交的 ZXID 和 Follower 上的 ZXID 进行比对，比对结果要么回滚，要么和 Leader 同步。

### 4. 服务注册、服务发现 过程

​		1.服务提供者启动时，会将其服务名称，ip地址注册到配置中心。

​		2.服务消费者在第一次调用服务时，会通过注册中心找到相应的服务的IP地址列表，并缓存到本地，以供后续使用。当消费者调用服务时，不会再去请求注册中心，而是直接通过负载均衡算法从IP列表中取一个服务提供者的服务器调用服务。

​		3.当服务提供者的某台服务器宕机或下线时，相应的ip会从服务提供者IP列表中移除。同时，注册中心会将新的服务IP地址列表发送给服务消费者机器，缓存在消费者本机。

​		4.当某个服务的所有服务器都下线了，那么这个服务也就下线了。

​		5.同样，当服务提供者的某台服务器上线时，注册中心会将新的服务IP地址列表发送给服务消费者机器，缓存在消费者本机。

​		6.服务提供方可以根据服务消费者的数量来作为服务下线的依据。

