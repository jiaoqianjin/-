# 大数据相关技术栈

![img](https://gitee.com/jiao_qianjin/zhishiku/raw/master/img/20211102134811.png)

## 知其然

### 大数据概念

> 大数据（Big Data）：指**无法在一定时间范围内**用常规软件工具进行捕捉、管理和处理的数据集合，是需要新处理模式才能具有更强的决策力、洞察发现力和流程优化能力的**海量、高增长率和多样化**的**信息资产**。

按顺序给出数据存储单位：bit、Byte、KB、MB、GB、**TB、PB、EB**、ZB、YB、BB、NB、DB。

大数据主要解决，**海量数据的采集、存储和分析计算问题**。

### 大数据特点

**1、Volume（大量）**

截至目前，人类生产的所有印刷材料的数据量是200PB，而历史上全人类总共说过的话的数据量大约是5EB。当前，典型个人计算机硬盘的容量为TB量级，而**一些大企业的数据量已经接近EB量级**。

**2、Velocity（高速）**

这是大数据区分于传统数据挖掘的最显著特征。根据IDC的“数字宇宙”的报告，预计到2025年，全球数据使用量将达到163ZB。在如此海量的数据面前，处理数据的效率就是企业的生命。

天猫双十一：2017年3分01秒，天猫交易额超过100亿
2020年96秒，天猫交易额超过100亿

**3、Variety（多样）**

类型的多样性也让数据被分为结构化数据和非结构化数据。相对于以往便于存储的**以数据库/文本为主的结构化数据**，**非结构化**数据越来越多，包括**网络日志、音频、视频、图片、地理位置信息**等，这些多类型的数据对数据的处理能力提出了更高要求。

**4、Value（低价值密度）**

**价值密度的高低与数据总量的大小成反比。如何快速对有价值数据“提纯”成为目前大数据背景下待解决的难题。**

总结：

- **大数据量的存储**
- **高效的数据处理**
- **多样类型的数据**
- **快速提取有价值的信息**

### 大数据的应用场景

1、抖音：推荐的都是你喜欢的视频

2、电商站内广告推荐：给用户推荐可能喜欢的商品

3、零售：分析用户消费习惯，为用户购买商品提供方便，从而提升商品销量。用户常买的，有关联的商品放在一起（外国经典案例，纸尿布+啤酒）

4、物流仓储：京东物流，上午下单下午送达、下午下单次日上午送达。不同地区的仓库结合当地特点存储相应的物资

5、保险：海量数据挖掘及风险预测，助力保险行业精准营销，提升精细化定价能力。

6、金融：多维度体现用户特征，帮助金融机构推荐优质客户，防范欺诈风险。

7、房产：大数据全面助力房地产行业，打造精准投策与营销，选出更合适的地，建造更合适的楼，卖给更合适的人。

8、人工智能+ 5G + 物联网+ 虚拟与现实



### 业务架构图

![img](https://gitee.com/jiao_qianjin/zhishiku/raw/master/img/20211102135006.png)

## 一、Sqoop

**Sqoop**，Sqoop(发音：skup)是一款开源的工具，主要用于在**Hadoop(Hive)与传统的数据库(mysql、postgresql...)间进行数据的传递**，可以将一个关系型数据库（例如 ： MySQL ,Oracle ,Postgres等）中的数据导进到Hadoop的HDFS中，也可以将HDFS的数据导进到关系型数据库中。

## 二、Flume

Flume是Cloudera提供的一个高可用的，高可靠的，分布式的海量日志采集、聚合和传输的系统，Flume支持在日志系统中定制各类数据发送方，用于收集数据；同时，Flume提供对数据进行简单处理，并写到各种数据接受方（可定制）的能力。

Flume最主要的作用就是，**实时读取服务器本地磁盘的数据，将数据写入到HDFS**。

![Flume作用](https://gitee.com/jiao_qianjin/zhishiku/raw/master/img/20211102151836.png)

## 三、Kafka

**Kafka是一种高吞吐量的分布式发布订阅消息系统，它可以处理消费者在网站中的所有动作流数据。**

说白了就是一个MQ消息系统，和Java中常用RabbitMQ、RocketMQ是一样的，只是各自的侧重点不一样，**Kafka侧重点在高吞吐量，可以处理海量的数据。**

### 1. 什么是Kafka

Kafka是最初由Linkedin公司开发，是一个分布式、分区的、多副本的、多订阅者，**基于zookeeper协调的分布式日志系统（也可以当做MQ系统）**，**常见可以用于web/nginx日志、访问日志，消息服务等等**，Linkedin于2010年贡献给了Apache基金会并成为顶级开源项目。

主要应用场景是：日志收集系统和消息系统。

Kafka主要设计目标如下：

- 以时间复杂度为O(1)的方式提供消息持久化能力，即使对TB级以上数据也能保证常数时间的访问性能。
- 高吞吐率。即使在非常廉价的商用机器上也能做到单机支持每秒100K条消息的传输。
- 支持Kafka Server间的消息分区，及分布式消费，同时保证每个partition内的消息顺序传输。
- 同时支持离线数据处理和实时数据处理。
- Scale out:支持在线水平扩展

### 2. Kafka的优点

#### 1 解耦

在项目启动之初来预测将来项目会碰到什么需求，是极其困难的。消息系统在处理过程中间插入了一个隐含的、基于数据的接口层，两边的处理过程都要实现这一接口。这允许你独立的扩展或修改两边的处理过程，只要确保它们遵守同样的接口约束。

#### 2 冗余（副本）

有些情况下，处理数据的过程会失败。除非数据被持久化，否则将造成丢失。消息队列把数据进行持久化直到它们已经被完全处理，通过这一方式规避了数据丢失风险。许多消息队列所采用的"插入-获取-删除"范式中，在把一个消息从队列中删除之前，需要你的处理系统明确的指出该消息已经被处理完毕，从而确保你的数据被安全的保存直到你使用完毕。

#### 3 扩展性

因为消息队列解耦了你的处理过程，所以增大消息入队和处理的频率是很容易的，只要另外增加处理过程即可。不需要改变代码、不需要调节参数。扩展就像调大电力按钮一样简单。

#### 4 灵活性&峰值处理能力

在访问量剧增的情况下，应用仍然需要继续发挥作用，但是这样的突发流量并不常见；如果为以能处理这类峰值访问为标准来投入资源随时待命无疑是巨大的浪费。使用消息队列能够使关键组件顶住突发的访问压力，而不会因为突发的超负荷的请求而完全崩溃。

#### 5 可恢复性

系统的一部分组件失效时，不会影响到整个系统。消息队列降低了进程间的耦合度，所以即使一个处理消息的进程挂掉，加入队列中的消息仍然可以在系统恢复后被处理。

#### 6 顺序保证

在大多使用场景下，数据处理的顺序都很重要。大部分消息队列本来就是排序的，并且能保证数据会按照特定的顺序来处理。Kafka保证一个Partition内的消息的有序性。

#### 7 缓冲

在任何重要的系统中，都会有需要不同的处理时间的元素。例如，加载一张图片比应用过滤器花费更少的时间。消息队列通过一个缓冲层来帮助任务最高效率的执行———写入队列的处理会尽可能的快速。该缓冲有助于控制和优化数据流经过系统的速度。

#### 8 异步通信

很多时候，用户不想也不需要立即处理消息。消息队列提供了异步处理机制，允许用户把一个消息放入队列，但并不立即处理它。想向队列中放入多少消息就放多少，然后在需要的时候再去处理它们。

### 3. MQ性能对比

![image-20211019210924108](https://gitee.com/jiao_qianjin/zhishiku/raw/master/img/20211102135349.png)

​		一般的业务系统要引入 MQ，最早大家都用 ActiveMQ，但是现在确实大家用的不多了，没经过大规模吞吐量场景的验证，社区也不是很活跃；


​		后来大家开始用 RabbitMQ，但是确实 erlang 语言阻止了大量的 Java 工程师去深入研究和掌控它，对公司而言，几乎处于不可控的状态，但是确实人家是开源的，比较稳定的支持，活跃度也高；

​		不过现在确实越来越多的公司会去用 RocketMQ，确实很不错，毕竟是阿里出品，但社区可能有突然黄掉的风险（目前 RocketMQ 已捐给 Apache，但 GitHub 上的活跃度其实不算高）对自己公司技术实力有绝对自信的，推荐用 RocketMQ，否则回去老老实实用 RabbitMQ 吧，人家有活跃的开源社区，绝对不会黄。

​		**所以中小型公司，技术实力较为一般，技术挑战不是特别高，用 RabbitMQ 是不错的选择；大型公司，基础架构研发实力较强，用 RocketMQ 是很好的选择。**
​		如果是**大数据领域的实时计算、日志采集等场景，用 Kafka 是业内标准的，绝对没问题，社区活跃度很高**，绝对不会黄，何况几乎是全世界这个领域的事实性规范。

## 四、Hadoop

[Hadoop文档](https://hadoop.apache.org/docs/r1.0.4/cn/)

### 1. 是什么

Hadoop是一个由Apache基金会所开发的**分布式系统基础架构**。

用户可以在不了解分布式底层细节的情况下，开发分布式程序。充分利用集群的威力进行高速运算和存储。

Hadoop实现了一个**分布式文件系统**（ Distributed File System），其中一个组件是HDFS（Hadoop Distributed File System）。

**HDFS有高容错性的特点**，并且设计用来部署在低廉的（low-cost）硬件上；而且它提供高吞吐量（high throughput）来访问应用程序的数据，适合那些有着超大数据集（large data set）的应用程序。HDFS放宽了（relax）POSIX的要求，可以以流的形式访问（streaming access）文件系统中的数据。

Hadoop的框架最核心的设计就是：[HDFS](https://baike.baidu.com/item/HDFS/4836121)和[MapReduce](https://baike.baidu.com/item/MapReduce/133425)。HDFS为海量的数据提供了存储，而MapReduce则为海量的数据提供了计算 。

![image-20211023090732487](https://gitee.com/jiao_qianjin/zhishiku/raw/master/img/20211023090732.png)

### 2. 解决了什么问题

​	**主要解决了海量数据的存储、分析和学习问题。**

​	因为随着数据的爆炸式增长，一味地靠硬件提高数据处理效率及增加存储量，不仅成本高，处理高维数据的效率也不会提高很多，遇到了瓶颈，**hadoop的搭建只需要普通的pc机，它的hdfs提供了分布式文件系统，mapreduce是一个并行编程模型，为程序员提供了编程接口，两者都屏蔽了分布式及并行底层的细节问题，用户使用起来简单方便。**

**能干什么**

- **大数据存储：**分布式存储
- **日志处理**：擅长日志分析
- **ETL**：数据抽取到oracle、mysql、DB2、mongdb及主流数据库
- **机器学习**： 比如Apache Mahout项目
- **搜索引擎**：Hadoop + lucene实现
- **数据挖掘**：目前比较流行的广告推荐，个性化广告推荐

Hadoop是专为离线和大规模数据分析而设计的，并不适合那种对几个记录随机读写的在线事务处理模式。

### 3. 有怎样的优缺点？

#### 优势：

1）**高可靠性：**Hadoop底层维护多个数据副本，所以即使Hadoop某个计算元 素或存储出现故障，也不会导致数据的丢失。

![image-20211023090229832](https://gitee.com/jiao_qianjin/zhishiku/raw/master/img/20211023090238.png) 

2）**高扩展性：**在集群间分配任务数据，可方便的扩展数以千计的节点。

![image-20211023090543686](https://gitee.com/jiao_qianjin/zhishiku/raw/master/img/20211023090543.png) 

3）**高效性：**在MapReduce的思想下，Hadoop是并行工作的，以加快任务处理速度。

![image-20211023090605901](https://gitee.com/jiao_qianjin/zhishiku/raw/master/img/20211023090605.png) 

4）**高容错性：**能够自动将失败的任务重新分配。 

![image-20211023090650965](https://gitee.com/jiao_qianjin/zhishiku/raw/master/img/20211023090651.png) 

#### 劣势：

**1）不能做到低延迟**

　　由于hadoop针对高数据吞吐量做了优化，牺牲了获取数据的延迟，所以对于低延迟数据访问，不适合hadoop，对于低延迟的访问需求，HBase是更好的选择，

**2）不适合大量的小文件存储**

　　由于namenode将文件系统的元数据存储在内存中，因此该文件系统所能存储的文件总数受限于namenode的内存容量，根据经验，每个文件、目录和数据块的存储信息大约占150字节。因此，如果大量的小文件存储，每个小文件会占一个数据块，会使用大量的内存，有可能超过当前硬件的能力。

**3）不适合多用户写入文件，修改文件**

　　Hadoop2.0虽然支持文件的追加功能，但是还是不建议对HDFS上的 文件进行修改，因为效率低。

　　对于上传到HDFS上的文件，不支持修改文件，HDFS适合一次写入，多次读取的场景。

　　HDFS不支持多用户同时执行写操作，即同一时间，只能有一个用户执行写操作。

## 五、Hive

### 1. 什么是Hive

hive是基于Hadoop的一个**数据仓库工具**，用来进行数据提取、转化、加载，这是一种可以存储、查询和分析存储在Hadoop中的大规模数据的机制。

hive数据仓库工具能**将结构化的数据文件映射为一张数据库表，并提供SQL查询功能**，能将SQL语句转变成MapReduce任务来执行。

### 2. Hive 的优缺点

#### 优点

- 操作接口采用 **类 SQL 语法**，提供快速开发的能力（简单、容易上手）。 
- **避免了去写 MapReduce**，减少开发人员的学习成本。 
- Hive可以处理大数据量。
- Hive 支持用户自定义函数，用户可以根据自己的需求来实现自己的函数。 

#### 缺点

- **Hive 的 HQL 表达能力有限** 
  - 迭代式算法无法表达 
  - 数据挖掘方面不擅长，由于 MapReduce 数据处理流程的限制，效率更高的算法却无法实现。 
- **Hive 的效率比较低** 
  - Hive 自动生成的 MapReduce 作业，通常情况下不够智能化 
  - Hive 调优比较困难，粒度较粗 
- **Hive的执行延迟比较高。**

### Hive的特点

1）**可扩展**

​	Hive可以自由的扩展集群的规模，一般情况下不需要重启服务。

2）**延展性**

​	Hive支持用户自定义函数，用户可以根据自己的需求来实现自己的函数。

3）**容错**

​	良好的容错性，节点出现问题SQL仍可完成执行。

## 六、Hbase

### 1. Hbase是什么

HBase是一种构建在HDFS之上的**分布式、面向列**的存储系统。在需要实时读写、随机访问超大规模数据集时，可以使用HBase。

### 2. HBase的特点

- **大**：一个表可以有上亿行，上百万列。
- **面向列**：面向列表（簇）的存储和权限控制，列（簇）独立检索。
- **稀疏：**对于为空（NULL）的列，并不占用存储空间，因此，表可以设计的非常稀疏。
- **无模式**：每一行都有一个可以排序的主键和任意多的列，列可以根据需要动态增加，同一张表中不同的行可以有截然不同的列。
- **数据多版本**：每个单元中的数据可以有多个版本，默认情况下，版本号自动分配，版本号就是单元格插入时的时间戳。
- **数据类型单一**：HBase中的数据都是字符串，没有类型。

### 3. HBase的高并发和实时处理数据

Hadoop是一个高容错、高延时的分布式文件系统和高并发的批处理系统，不适用于提供实时计算；

**HBase是可以提供实时计算的分布式数据库**，数据被保存在HDFS分布式文件系统上，由HDFS保证其高容错性。

## 七、ZooKeeper

**Apache ZooKeeper致力于开发和维护可实现高度可靠的分布式协调的开源服务器。**

### 1. 应用场景 

提供的服务包括：

- 统一命名服务
- 统一配置管理
- 统一集群管理
- 服务器节点动态上下线
- 软负载均衡等。 

### 2. ZooKeeper在大数据中的作用

​		在大数据生态里面的客户，hadoop、hbase、hive…组件都是分布式部署，**这些组件们利用zookeeper的服务做了一些维持自身平衡的事情**，比如**集群管理、master选举、消息发布订阅、数据存储、分布式锁**等等。作为整个集群的心脏的存在，zookeeper本身也是分布式，只有在`分布式`的基础上才能实现`高度可靠`，否则任何单点的可靠都是在耍流氓。

#### 1. hadoop

**Hadoop HA：**

​		不论是namenode的HA或是yarn的HA，都通过zkfc机制来选举控制只有一个active状态的namenode和resourcemanager在工作，**master的选举功能，采用的是排他锁完成的选举**，我们通过zk可视化客户端可以清晰地看到Znode的结构，yarn和hdfs的路径下各有一把锁的标记文件，同时文件的内容也带有active节点的信息。

**yarn application容错：**

​		在yarn上跑任务时，**所有application启动时都会把application的信息写入zk里面**，假如这时active状态的resourcemanager突然挂了，standby的转换成active状态后会接管挂之前的application，这样resourcemanager主从的切换对正在yarn运行的application不影响。

#### 2. hbase

**zk在hbase应用的功能主要有两个：**

1. hbase regionserver 向zookeeper注册，提供hbase regionserver状态信息（是否在线），HMaster通过watcher监听regionserver的存活情况，并不是HMaster跟Regionserver通过心跳机制检测。
2. HMaster启动时候会将hbase系统表-ROOT- 加载到 zookeeper cluster，通过zookeeper cluster可以获取当前系统表.META.的存储所对应的regionserver信息

#### 3. kafka

**zk在kafka的应用功能主要有三个：**

1. **broker的注册**：我们上面描述的zk一个基本的功能是做集群的管理，所有broker会把自己的id号注册进zk的Znode里面，通过事件监听的机制，各个broker之间都知道所有兄弟的存活情况。当有broker启动时，会在zk里面创建Znode，并通知其它broker；当有broker下线或挂掉时，同样会通知其它broker。
2. **topic的注册**：当topic创建时，kafka会把topic的name、partition、leader、topic的分布情况等信息写入zk里面，当broker退出时，会触发zookeeper更新其对应topic分区的isr列表，并决定是否需要做消费者的负载均衡。
3. **consumer的注册**：当有新的消费者消费kafka数据时，会在zk中创建Znode保存一些信息，节点路径为ls /consumers/{group_id}，其节点下有三个子节点，分别为[ids, owners, offsets]。在常用的offset的维护中，应用消费kafka数据时要设置参数enable.auto.commit为true才会自动更新offset。

#### 4. hive

**zk在hive的两个主要应用：**

**1. hiveserver2的选举**：利用zookeeper分布式锁机制

如果两个节点在zk中注册，会创建有序的临时节点，每个Znode都有一串数字后缀，zk默认是同一个锁路径下id最小的那个znode获取锁，也就是上图中的后缀000000228所代表的hiveserver2节点是主的状态，假如这个节点挂了，这个znode会自动删除，watcher机制会通知另一个hiveserver2上位。

**2. 表数据锁**：Hive 锁机制是为了让 Hive 支持并发读写的原子性而设计的 特性，比如，一个sql在insert数据，这时需要锁住表，不让其它sql去读取表数据，否则会有问题。等到释放锁之后，也就是insert完了其它客户端才能读取这个表

## 八、数据处理技术

像MapReduce、Spark、Storm/Flink都是用来处理数据的，比如数据清洗、计算、统计等等之类的。

### 8.1 MapReduce

#### 什么是MapReduce？

MapReduce 是一个**分布式运算程序**的编程框架，是用户开发“基于 Hadoop 的数据分析应用”的核心框架。 

MapReduce 核心功能是 **将用户编写的业务逻辑代码和自带默认组件整合成一个完整的分布式运算程序，并发运行在一个 Hadoop 集群上** 。 

#### MapReduce 的使用场景

核心思想：**如何把大问题分解成独立的小问题，再并行解决**。

典型场景：

**计算`URL`的访问频率**：搜索引擎的使用中，会遇到大量的`URL`的访问，所以，可以使用 `MapReduce` 来进行统计，得出（`URL`,次数）结果，在后续的分析中可以使用。

**Top K 问题**：在各种的文档分析，或者是不同的场景中，经常会遇到关于 `Top K` 的问题，例如输出这篇文章的出现前`5`个最多的词汇。这个时候也可以使用 `MapReduce`来进行统计。

#### MapReduce优缺点

##### 优点

1、**易于编程**： 用户只关心业务逻辑。 实现框架的接口。
2、**良好扩展性**：可以动态增加服务器，解决计算资源不够问题。
3、**高容错性**：任何一台机器挂掉，可以将任务转移到其他节点。
4、**适合海量数据计算**：（TB/PB） 几千台服务器共同计算。

##### 缺点

1、**不擅长实时计算。 Mysql**（在毫秒或者秒级内返回结果）
2、**不擅长流式计算。 Spark Streaming | flink 。**流式计算的输入数据是动态的，而 MapReduce 的输入数据集是静态的，不能动态变化。
3、**不擅长DAG有向无环图计算。spark 。** 多个应用程序存在依赖关系，后一个应用程序的输入为前一个的输出。在这种情况下，MapReduce 并不是不能做，而是使用后，每个 MapReduce 作业的输出结果都会写入到磁盘，会造成大量的磁盘 IO，导致性能非常的低下。 

### 8.2 Spark

#### 1. Spark是什么

- **Spark是一种快速、通用、可扩展的大数据分析引擎**，2009年诞生于加州大学伯克利分校AMPLab，2010年开源，2013年6月成为Apache孵化项目，2014年2月成为Apache顶级项目。
- **目前，Spark生态系统已经发展成为一个包含多个子项目的集合**，其中包含SparkSQL、SparkStreaming、GraphX、MLlib等子项目
- **Spark是基于内存计算的大数据并行计算框架**。Spark基于内存计算，提高了在大数据环境下数据处理的实时性，同时保证了高容错性和高可伸缩性，允许用户将Spark部署在大量廉价硬件之上，形成集群。
- **Spark得到了众多大数据公司的支持**，这些公司包括Hortonworks、IBM、Intel、Cloudera、MapR、Pivotal、百度、阿里、腾讯、京东、携程、优酷土豆。当前百度的Spark已应用于凤巢、大搜索、直达号、百度大数据等业务；阿里利用GraphX构建了大规模的图计算和图挖掘系统，实现了很多生产系统的推荐算法；腾讯Spark集群达到8000台的规模，是当前已知的世界上最大的Spark集群。

#### 2. Spark特点

**1．轻量级快速处理**
	大数据处理中速度往往被置于第一位，**Spark允许传统Hadoop集群中的应用程序在内存中以100倍的速度运行**，即使在磁盘上运行也能快10倍。Spark通过减少磁盘IO来达到性能的提升，它们将中间处理数据全部放到了内存中。Spark使用了RDD（Resilient Distributed Datasets）数据抽象，这允许它可以在内存中存储数据，只在需要时才持久化到磁盘。这种做法大大的减少了数据处理过程中磁盘的读写，大幅度的降低了运行时间。

**2．易于使用**
	**Spark支持多语言。**Spark允许Java、Scala、Python及R（Spark 1.4版最新支持），这允许更多的开发者在自己熟悉的语言环境下进行工作，普及了Spark的应用范围，它自带80多个高等级操作符，允许在shell中进行交互式查询，它多种使用模式的特点让应用更灵活。

**3．支持复杂查询**
**除了简单的map及reduce操作之外，Spark还支持filter、foreach、reduceByKey、aggregate以及SQL查询、流式查询等复杂查询**。Spark更为强大之处是用户可以在同一个工作流中无缝的搭配这些功能，例如Spark可以通过Spark Streaming（1.2.2小节对Spark Streaming有详细介绍）获取流数据，然后对数据进行实时SQL查询或使用MLlib库进行系统推荐，而且这些复杂业务的集成并不复杂，因为它们都基于RDD这一抽象数据集在不同业务过程中进行转换，转换代价小，体现了统一引擎解决不同类型工作场景的特点。有关Streaming技术以及MLlib库和RDD将会这之后几个章节进行详述。

**4．实时的流处理**
对比MapReduce只能处理离线数据，Spark还能支持实时流计算。Spark Streaming主要用来对数据进行实时处理，当然在YARN之后Hadoop也可以借助其他的工具进行流式计算。对于Spark Streaming，著名的大数据产品开发公司Cloudera曾经对Spark Streaming有如下评价：

​	1）简单、轻量且具备功能强大的API，Sparks Streaming允许用户快速开发流应用程序。

​	2）容错能力强，不像其他的流解决方案，比如使用Storm需要额外的配置，而Spark无需额外的代码和配置，因为直接使用其上层应用框架Spark Streaming就可以做大量的恢复和交付工作，让Spark的流计算更适应不同的需求。

​	3）集成性好，为流处理和批处理重用了同样的代码，甚至可以将流数据保存到历史数据中（如HDFS）。

**5．与已存Hadoop数据整合**
Spark不仅可以独立的运行（使用standalone模式），还可以运行在当下的YARN管理集群中。它还可以读取已有的任何Hadoop数据，这是个非常大的优势，它可以运行在任何Hadoop数据源上，比如HBase、HDFS等。如果合适的话，这个特性让用户可以轻易迁移已有Hadoop应用。

**6．活跃和不断壮大的社区**
Spark起源于2009年，当下已有超过50个机构730个工程师贡献过代码，与2014年6月相比2015年代码行数扩大了近三倍（数据源于Spark Summit 2015公布的数据），这是个惊人的增长。

#### 3. Spark缺点

1. **如果数据超过1T了基本就不能用spark了，还是会选择MapReduce**，MapReduce利用磁盘的高I/O操作实现并行计算确实在处理海量数据是无法取代的，但它在迭代计算中性能不足。（为什么数据过大不适用spark，**spark基于内存好也是内存，不好也是内存，如果数据过大，或导致OOM内存溢出等等，spark的程序就无法运行了，直接就会报错挂掉了**。虽然MapReduce运行数据相对spark很慢，但是至少他可以慢慢的跑不是吗？再慢至少能跑完。
2. 多人认为Spark SQL完全能够替代Hive的查询引擎，我认为肯定是不行的，因为Hive是一种基于HDFS的数据仓库， 并且提供了基于SQL模型的， 针对 存储了大数据的数据仓库， **进行分布式交互查询的查询引擎,有少量的Hive支持的高级特性,Spark SQL暂时还不支持**。当然Spark SQL相较于Hive查询引擎来说， 就是速度快，原因还是因为hive底层基于MapReduce

#### 4. 与hadoop对比

![Hadoop与Spark的区别](https://gitee.com/jiao_qianjin/zhishiku/raw/master/img/20211102144834.png)

从表1-1中可以看出，发展10余年的Hadoop解决了处理大数据的问题，但因其设计之初没有考虑到效率，导致在面对迭代计算问题时效率很低，主要原因归结于其**M/R计算模型太单一且计算过程中的Shuffle过程对本地硬盘的I/O消耗太大，不能适应复杂需求**。不仅如此，当Hadoop要面对SQL交互式查询场景、实时流处理场景以及机器学习场景就力不从心，不得不跟其他第三方应用框架结合，导致不同类型业务（如流处理和SQL交互查询）在衔接过程中因涉及不同的数据格式，数据在共享和转换过程中要消耗大量资源。

大家都知道内存计算速度比机械硬盘快几个数量级，**Spark作为基于内存计算大数据处理平台以其高速、多场景适用的特点逐渐脱颖而出，体现了一个堆栈来解决各种场景（One stack rule all）的宗旨。**

### 8.3 Flink

#### 什么是Flink？

Apache Flink 是一个**框架**和**分布式处理引擎**，用于**对无界和有界数据流进行状态计算**。

#### 为什么选择 Flink？

流数据更真实地反映了我们的生活方式

传统的数据架构是基于有限数据集的

优点：

- 低延迟
- 高吞吐
- 结果的准确性和良好的容错性

#### 流数据使用场景

**电商和市场营销：**数据报表、广告投放、业务流程需要

**物联网（IOT）：**传感器实时数据采集和显示、实时报警，交通运输业

**电信业：**基站流量调配

**银行和金融业：**实时结算和通知推送，实时检测异常行为

#### Flink 的主要特点

1. **事件驱动（Event-drive**n）
2. **基于流的世界观**
   1. 在 Flink 的世界观中，一切都是由流组成的，离线数据是有界的流；
   2. 实时数据是一个没有界限的流：这就是所谓的有界流和无界流
3. 分层API
   1. 越顶层越抽象，表达含义越简明，使用越方便
   2. 越底层越具体，表达能力越丰富，使用越灵活

其他特点：

1. 支持事件时间（event-time）和处理时间（processing-time）语义
2. 精确一次（exactly-once）的状态一致性保证
3. 低延迟，每秒处理数百万个事件，毫秒级延迟
4. 与众多常用存储系统的连接
5. 高可用，动态扩展，实现7*24小时全天候运行

#### Flink vs Spark Streaming

**数据模型**

- spark 采用 RDD 模型，spark streaming 的 DStream 实际上也就是一组 组小批数据 RDD 的集合
- flink 基本数据模型是数据流，以及事件（Event）序列

**运行时架构**

- spark 是批计算，将 DAG 划分为不同的 stage，一个完成后才可以计算下一个
- flink 是标准的流执行模式，一个事件在一个节点处理完后可以直接发往下一个节点进行处理

## 大数据技术生态

![image-20211023142247019](https://gitee.com/jiao_qianjin/zhishiku/raw/master/img/20211102145606.png)

图中涉及的技术名词解释如下：

**1）Sqoop：**Sqoop是一款开源的工具，主要用于在Hadoop、Hive与传统的数据库（MySQL）间进行数据的传递，可以将一个关系型数据库（例如 ：MySQL，Oracle 等）中的数据导进到Hadoop的HDFS中，也可以将HDFS的数据导进到关系型数据库中。

**2）Flume：**Flume是一个高可用的，高可靠的，分布式的海量日志采集、聚合和传输的系统，Flume支持在日志系统中定制各类数据发送方，用于收集数据； 

**3）Kafka：**Kafka是一种高吞吐量的分布式发布订阅消息系统； 

**4）Spark：**Spark是当前最流行的开源大数据内存计算框架。可以基于Hadoop上存储的大数据进行计算。

**5）Flink：**Flink是当前最流行的开源大数据内存计算框架。用于实时计算的场景较多。

**6）Oozie：**Oozie是一个管理Hadoop作业（job）的工作流程调度管理系统。

**7）Hbase：**HBase是一个分布式的、面向列的开源数据库。HBase不同于一般的关系数据库，它是一个适合于非结构化数据存储的数据库。

**8）Hive：**Hive是基于Hadoop的一个数据仓库工具，可以将结构化的数据文件映射为一张数据库表，并提供简单的SQL查询功能，可以将SQL语句转换为MapReduce任务进行运行。其优点是学习成本低，可以通过类SQL语句快速实现简单的MapReduce统计，不必开发专门的MapReduce应用，十分适合数据仓库的统计分析。

**9）ZooKeeper：**它是一个针对大型分布式系统的可靠协调系统，提供的功能包括：配置维护、名字服务、分布式同步、组服务等。





---



![img](https://gitee.com/jiao_qianjin/zhishiku/raw/master/img/20211102145526.jpeg)

蓝色部分，是Hadoop生态系统组件，黄色部分是Spark生态组件，虽然他们是两种不同的大数据处理框架，但它们不是互斥的，Spark与hadoop 中的MapReduce是一种相互共生的关系。Hadoop提供了Spark许多没有的功能，比如分布式文件系统，而Spark 提供了实时内存计算，速度非常快。有一点大家要注意，Spark并不是一定要依附于Hadoop才能生存，除了Hadoop的HDFS，还可以基于其他的云平台

### 趋势

1. Spark在崛起，hadoop和Storm中的一些组件在消退
2. HSQL未来可能会被Spark SQL替代，现在很多企业都是HIVE SQL和Spark SQL两种工具共存，当Spark SQL逐步成熟的时候，就有可能替换HSQL
3. MapReduce也有可能被Spark 替换，趋势是这样，但目前Spark还不够成熟稳定
4. Hadoop中的算法库Mahout正被Spark中的算法库MLib所替代
5. Storm会被Spark Streaming替换吗?Storm虽然不是hadoop生态中的一员，由于Spark和hadoop天衣无缝的结合，Spark在逐步的走向成熟和稳定，其生态组件也在逐步的完善，是冉冉升起的新星，Storm会逐步被挤压而走向衰退