# 大数据相关技术栈扫盲

![img](https://gitee.com/jiao_qianjin/zhishiku/raw/master/img/20211023091646.png)

## 一、Hadoop

[Hadoop文档](https://hadoop.apache.org/docs/r1.0.4/cn/)

### 1. 是什么

Hadoop是一个由Apache基金会所开发的**[分布式系统](https://baike.baidu.com/item/分布式系统/4905336)基础架构**。

用户可以在不了解分布式底层细节的情况下，开发分布式程序。充分利用集群的威力进行高速运算和存储。

Hadoop实现了一个**[分布式文件系统](https://baike.baidu.com/item/分布式文件系统/1250388)**（ Distributed File System），其中一个组件是HDFS（Hadoop Distributed File System）。

HDFS有高[容错性](https://baike.baidu.com/item/容错性/9131391)的特点，并且设计用来部署在低廉的（low-cost）硬件上；而且它提供高吞吐量（high throughput）来访问[应用程序](https://baike.baidu.com/item/应用程序/5985445)的数据，适合那些有着超大数据集（large data set）的应用程序。HDFS放宽了（relax）[POSIX](https://baike.baidu.com/item/POSIX/3792413)的要求，可以以流的形式访问（streaming access）文件系统中的数据。

Hadoop的框架最核心的设计就是：[HDFS](https://baike.baidu.com/item/HDFS/4836121)和[MapReduce](https://baike.baidu.com/item/MapReduce/133425)。HDFS为海量的数据提供了存储，而MapReduce则为海量的数据提供了计算 。

![image-20211023090732487](https://gitee.com/jiao_qianjin/zhishiku/raw/master/img/20211023090732.png)

### 2. 解决了什么问题

​	**主要解决了海量数据的存储、分析和学习问题。**

​	因为随着数据的爆炸式增长，一味地靠硬件提高数据处理效率及增加存储量，不仅成本高，处理高维数据的效率也不会提高很多，遇到了瓶颈，hadoop的搭建只需要普通的pc机，它的hdfs提供了分布式文件系统，mapreduce是一个并行编程模型，为程序员提供了编程接口，两者都屏蔽了分布式及并行底层的细节问题，用户使用起来简单方便。

**能干什么**

- **大数据存储：**分布式存储
- **日志处理**：擅长日志分析
- **ETL**：数据抽取到oracle、mysql、DB2、mongdb及主流数据库
- **机器学习**： 比如Apache Mahout项目
- **搜索引擎**：Hadoop + lucene实现
- **数据挖掘**：目前比较流行的广告推荐，个性化广告推荐

Hadoop是专为离线和大规模数据分析而设计的，并不适合那种对几个记录随机读写的在线事务处理模式。

### 3. 有怎样的优缺点？

#### 优势：

1）**高可靠性：**Hadoop底层维护多个数据副本，所以即使Hadoop某个计算元 素或存储出现故障，也不会导致数据的丢失。

![image-20211023090229832](https://gitee.com/jiao_qianjin/zhishiku/raw/master/img/20211023090238.png) 

2）**高扩展性：**在集群间分配任务数据，可方便的扩展数以千计的节点。

![image-20211023090543686](https://gitee.com/jiao_qianjin/zhishiku/raw/master/img/20211023090543.png) 

3）**高效性：**在MapReduce的思想下，Hadoop是并行工作的，以加快任务处理速度。

![image-20211023090605901](https://gitee.com/jiao_qianjin/zhishiku/raw/master/img/20211023090605.png) 

4）**高容错性：**能够自动将失败的任务重新分配。 

![image-20211023090650965](https://gitee.com/jiao_qianjin/zhishiku/raw/master/img/20211023090651.png) 

#### 劣势：

**1）不能做到低延迟**

　　由于hadoop针对高数据吞吐量做了优化，牺牲了获取数据的延迟，所以对于低延迟数据访问，不适合hadoop，对于低延迟的访问需求，HBase是更好的选择，

**2）不适合大量的小文件存储**

　　由于namenode将文件系统的元数据存储在内存中，因此该文件系统所能存储的文件总数受限于namenode的内存容量，根据经验，每个文件、目录和数据块的存储信息大约占150字节。因此，如果大量的小文件存储，每个小文件会占一个数据块，会使用大量的内存，有可能超过当前硬件的能力。

**3）不适合多用户写入文件，修改文件**

　　Hadoop2.0虽然支持文件的追加功能，但是还是不建议对HDFS上的 文件进行修改，因为效率低。

　　对于上传到HDFS上的文件，不支持修改文件，HDFS适合一次写入，多次读取的场景。

　　HDFS不支持多用户同时执行写操作，即同一时间，只能有一个用户执行写操作。



## 二、Hbase

### 1. Hbase是什么

HBase是一种构建在HDFS之上的**分布式、面向列**的存储系统。在需要实时读写、随机访问超大规模数据集时，可以使用HBase。

### 2. HBase的特点

- **大**：一个表可以有上亿行，上百万列。
- **面向列**：面向列表（簇）的存储和权限控制，列（簇）独立检索。
- **稀疏：**对于为空（NULL）的列，并不占用存储空间，因此，表可以设计的非常稀疏。
- **无模式**：每一行都有一个可以排序的主键和任意多的列，列可以根据需要动态增加，同一张表中不同的行可以有截然不同的列。
- **数据多版本**：每个单元中的数据可以有多个版本，默认情况下，版本号自动分配，版本号就是单元格插入时的时间戳。
- **数据类型单一**：HBase中的数据都是字符串，没有类型。

### 3. HBase的高并发和实时处理数据

Hadoop是一个高容错、高延时的分布式文件系统和高并发的批处理系统，不适用于提供实时计算；HBase是可以提供实时计算的分布式数据库，数据被保存在HDFS分布式文件系统上，由HDFS保证其高容错性。

## 三、Hive

### 1. 什么是Hive

Hive是基于Hadoop的一个数据仓库工具，可以将结构化的数据文件映射为一张数据库表，并提供类SQL查询功能。

### 2. 解决了什么问题

直接使用hadoop所面临的问题

- 人员学习成本太高
- 项目周期要求太短
- MapReduce实现复杂查询逻辑开发难度太大



操作接口采用类SQL语法，提供快速开发的能力。

避免了去写MapReduce，减少开发人员的学习成本。

扩展功能很方便。

### 3 Hive的特点

1）可扩展

​	Hive可以自由的扩展集群的规模，一般情况下不需要重启服务。

2）延展性

​	Hive支持用户自定义函数，用户可以根据自己的需求来实现自己的函数。

3）容错

​	良好的容错性，节点出现问题SQL仍可完成执行。

###  4. Hive与Hadoop的关系

Hive利用HDFS存储数据，利用MapReduce查询数据

 ![img](https://gitee.com/jiao_qianjin/zhishiku/raw/master/img/20211023101404.png)

## 四、flink

### 1. flink是什么

**Flink是分布式、高性能、随时可以用以及准确的流处理应用程序打造的开源流处理框架**。

Apache Flink是一个框架和分布式处理引擎，用于对无界和有界数据流进行有状态计算。Flink被设计在所有常见的集群环境中运行，以内存执行速度和任意规模来执行计算。



## 五、ElasticSearch

### 1. ElasticSearch是什么

**Elasticsearch 是一个分布式可扩展的实时搜索和分析引擎**，一个建立在全文搜索引擎 Apache Lucene(TM) 基础上的搜索引擎.当然 Elasticsearch 并不仅仅是 Lucene 那么简单，它不仅包括了全文搜索功能，还可以进行以下工作:

- 分布式实时文件存储，并将每一个字段都编入索引，使其可以被搜索。
- 实时分析的分布式搜索引擎。
- 可以扩展到上百台服务器，处理PB级别的结构化或非结构化数据。

### 2. ElasticSearch有什么优势呢？

1、**很简便的横向扩容，分布式的架构，可以轻松地对资源进行横向纵向扩缩容，可以满足不同数据量级及查询场景对硬件资源的需求**。能由数百台到万台机器搭建满足PB级的快速搜索，也能搭建单机版服务小公司。

2、**查询速度快**：ES底层采用Lucene作为搜索引擎，并在此之上做了多重优化，保证了用户对数据查询数据的需求。可"代替"传统关系型数据库，也可用于复杂数据分析，海量数据的近实时处理等。

3、**相关性高**：ES内部提供了完善的评分机制，会根据分词出现的频次等信息对文档进行相关性排序，保证相关性越高的文档排序越靠前。另外还提供了包括模糊查询，前缀查询，通配符查询等在内的多种查询手段，帮助用户快速高效地进行检索。

4、**功能点多但使用比较简便，开箱即用，性能优化比较简单**

5、**生态圈丰富，社区活跃，适配多种工具**处理日志和输出到Elasticsearch，您可以使用日志记录工具，如Logstash（www.elastic.co/products/logstash），搜索和可视化界面分析这些日志，你可以使用Kibana（www.elastic.co/产品/ kibana），即传说中的ELK技术栈。另外当前主流的大数据框架也几乎都支持ES，比如Flink和ES就是个完美搭档。

### 3. 什么时候应该用ElasticSearch?

1、典型搜索场景：闭着眼用它！

2、典型日志分析场景：闭着眼用它！

3、关系型数据库查询有瓶颈：考虑下用它！为啥是考虑？ES的优点在于查询，然而实践证明，在被作为数据库来使用，即写完马上查询会有延迟。

4、数据分析场景：考虑下用它！为啥是考虑？简单通用的场景需求可以大规模使用，但在特定业务场景领域，还是要选择更加专业的数据产品，如复杂聚合，ClickHouse相比 Elasticserach 做亿级别数据深度聚合需求会更加合适。

## 六、Kafka

### 1. 什么是Kafka

Kafka是最初由Linkedin公司开发，是一个分布式、分区的、多副本的、多订阅者，基于zookeeper协调的分布式日志系统（也可以当做MQ系统），常见可以用于web/nginx日志、访问日志，消息服务等等，Linkedin于2010年贡献给了Apache基金会并成为顶级开源项目。

主要应用场景是：日志收集系统和消息系统。

Kafka主要设计目标如下：

- 以时间复杂度为O(1)的方式提供消息持久化能力，即使对TB级以上数据也能保证常数时间的访问性能。
- 高吞吐率。即使在非常廉价的商用机器上也能做到单机支持每秒100K条消息的传输。
- 支持Kafka Server间的消息分区，及分布式消费，同时保证每个partition内的消息顺序传输。
- 同时支持离线数据处理和实时数据处理。
- Scale out:支持在线水平扩展

### 2. Kafka的优点

#### 1 解耦

在项目启动之初来预测将来项目会碰到什么需求，是极其困难的。消息系统在处理过程中间插入了一个隐含的、基于数据的接口层，两边的处理过程都要实现这一接口。这允许你独立的扩展或修改两边的处理过程，只要确保它们遵守同样的接口约束。

#### 2 冗余（副本）

有些情况下，处理数据的过程会失败。除非数据被持久化，否则将造成丢失。消息队列把数据进行持久化直到它们已经被完全处理，通过这一方式规避了数据丢失风险。许多消息队列所采用的"插入-获取-删除"范式中，在把一个消息从队列中删除之前，需要你的处理系统明确的指出该消息已经被处理完毕，从而确保你的数据被安全的保存直到你使用完毕。

#### 3 扩展性

因为消息队列解耦了你的处理过程，所以增大消息入队和处理的频率是很容易的，只要另外增加处理过程即可。不需要改变代码、不需要调节参数。扩展就像调大电力按钮一样简单。

#### 4 灵活性&峰值处理能力

在访问量剧增的情况下，应用仍然需要继续发挥作用，但是这样的突发流量并不常见；如果为以能处理这类峰值访问为标准来投入资源随时待命无疑是巨大的浪费。使用消息队列能够使关键组件顶住突发的访问压力，而不会因为突发的超负荷的请求而完全崩溃。

#### 5 可恢复性

系统的一部分组件失效时，不会影响到整个系统。消息队列降低了进程间的耦合度，所以即使一个处理消息的进程挂掉，加入队列中的消息仍然可以在系统恢复后被处理。

#### 6 顺序保证

在大多使用场景下，数据处理的顺序都很重要。大部分消息队列本来就是排序的，并且能保证数据会按照特定的顺序来处理。Kafka保证一个Partition内的消息的有序性。

#### 7 缓冲

在任何重要的系统中，都会有需要不同的处理时间的元素。例如，加载一张图片比应用过滤器花费更少的时间。消息队列通过一个缓冲层来帮助任务最高效率的执行———写入队列的处理会尽可能的快速。该缓冲有助于控制和优化数据流经过系统的速度。

#### 8 异步通信

很多时候，用户不想也不需要立即处理消息。消息队列提供了异步处理机制，允许用户把一个消息放入队列，但并不立即处理它。想向队列中放入多少消息就放多少，然后在需要的时候再去处理它们。

### 3. MQ性能对比

![image-20211019210924108](https://gitee.com/jiao_qianjin/zhishiku/raw/master/img/20211023140756.png)

​		一般的业务系统要引入 MQ，最早大家都用 ActiveMQ，但是现在确实大家用的不多了，没经过大规模吞吐量场景的验证，社区也不是很活跃；


​		后来大家开始用 RabbitMQ，但是确实 erlang 语言阻止了大量的 Java 工程师去深入研究和掌控它，对公司而言，几乎处于不可控的状态，但是确实人家是开源的，比较稳定的支持，活跃度也高；

​		不过现在确实越来越多的公司会去用 RocketMQ，确实很不错，毕竟是阿里出品，但社区可能有突然黄掉的风险（目前 RocketMQ 已捐给 Apache，但 GitHub 上的活跃度其实不算高）对自己公司技术实力有绝对自信的，推荐用 RocketMQ，否则回去老老实实用 RabbitMQ 吧，人家有活跃的开源社区，绝对不会黄。

​		**所以中小型公司，技术实力较为一般，技术挑战不是特别高，用 RabbitMQ 是不错的选择；大型公司，基础架构研发实力较强，用 RocketMQ 是很好的选择。**
​		如果是**大数据领域的实时计算、日志采集等场景，用 Kafka 是业内标准的，绝对没问题，社区活跃度很高**，绝对不会黄，何况几乎是全世界这个领域的事实性规范。

## 七、ZooKeeper

**Apache ZooKeeper致力于开发和维护可实现高度可靠的分布式协调的开源服务器。**

### 1. 应用场景 

提供的服务包括：

- 统一命名服务
- 统一配置管理
- 统一集群管理
- 服务器节点动态上下线
- 软负载均衡等。 

### 2. ZooKeeper在大数据中的作用

​		在大数据生态里面的客户，hadoop、hbase、hive…组件都是分布式部署，**这些组件们利用zookeeper的服务做了一些维持自身平衡的事情**，比如集群管理、master选举、消息发布订阅、数据存储、分布式锁等等。作为整个集群的心脏的存在，zookeeper本身也是分布式，只有在`分布式`的基础上才能实现`高度可靠`，否则任何单点的可靠都是在耍流氓。

#### 1. hdoop

**Hadoop HA：**

​		不论是namenode的HA或是yarn的HA，都通过zkfc机制来选举控制只有一个active状态的namenode和resourcemanager在工作，master的选举功能，采用的是排他锁完成的选举，我们通过zk可视化客户端可以清晰地看到Znode的结构，yarn和hdfs的路径下各有一把锁的标记文件，同时文件的内容也带有active节点的信息。

**yarn application容错：**

​		在yarn上跑任务时，所有application启动时都会把application的信息写入zk里面，假如这时active状态的resourcemanager突然挂了，standby的转换成active状态后会接管挂之前的application，这样resourcemanager主从的切换对正在yarn运行的application不影响。

#### 2. hbase

**zk在hbase应用的功能主要有两个：**

1. hbase regionserver 向zookeeper注册，提供hbase regionserver状态信息（是否在线），HMaster通过watcher监听regionserver的存活情况，并不是HMaster跟Regionserver通过心跳机制检测。
2. HMaster启动时候会将hbase系统表-ROOT- 加载到 zookeeper cluster，通过zookeeper cluster可以获取当前系统表.META.的存储所对应的regionserver信息

#### 3. kafka

**zk在kafka的应用功能主要有三个：**

1. **broker的注册**：我们上面描述的zk一个基本的功能是做集群的管理，所有broker会把自己的id号注册进zk的Znode里面，通过事件监听的机制，各个broker之间都知道所有兄弟的存活情况。当有broker启动时，会在zk里面创建Znode，并通知其它broker；当有broker下线或挂掉时，同样会通知其它broker。
2. **topic的注册**：当topic创建时，kafka会把topic的name、partition、leader、topic的分布情况等信息写入zk里面，当broker退出时，会触发zookeeper更新其对应topic分区的isr列表，并决定是否需要做消费者的负载均衡。
3. **consumer的注册**：当有新的消费者消费kafka数据时，会在zk中创建Znode保存一些信息，节点路径为ls /consumers/{group_id}，其节点下有三个子节点，分别为[ids, owners, offsets]。在常用的offset的维护中，应用消费kafka数据时要设置参数enable.auto.commit为true才会自动更新offset。

#### 4. hive

**zk在hive的两个主要应用：**

**1. hiveserver2的选举**：利用zookeeper分布式锁机制

如果两个节点在zk中注册，会创建有序的临时节点，每个Znode都有一串数字后缀，zk默认是同一个锁路径下id最小的那个znode获取锁，也就是上图中的后缀000000228所代表的hiveserver2节点是主的状态，假如这个节点挂了，这个znode会自动删除，watcher机制会通知另一个hiveserver2上位。

**2. 表数据锁**：Hive 锁机制是为了让 Hive 支持并发读写的原子性而设计的 特性，比如，一个sql在insert数据，这时需要锁住表，不让其它sql去读取表数据，否则会有问题。等到释放锁之后，也就是insert完了其它客户端才能读取这个表

## 八 总结

### 大数据技术生态

![image-20211023142247019](https://gitee.com/jiao_qianjin/zhishiku/raw/master/img/20211023142247.png)

图中涉及的技术名词解释如下：

**1）Sqoop：**Sqoop是一款开源的工具，主要用于在Hadoop、Hive与传统的数据库（MySQL）间进行数据的传递，可以将一个关系型数据库（例如 ：MySQL，Oracle 等）中的数据导进到Hadoop的HDFS中，也可以将HDFS的数据导进到关系型数据库中。

**2）Flume：**Flume是一个高可用的，高可靠的，分布式的海量日志采集、聚合和传输的系统，Flume支持在日志系统中定制各类数据发送方，用于收集数据； 

**3）Kafka：**Kafka是一种高吞吐量的分布式发布订阅消息系统； 

**4）Spark：**Spark是当前最流行的开源大数据内存计算框架。可以基于Hadoop上存储的大数据进行计算。

**5）Flink：**Flink是当前最流行的开源大数据内存计算框架。用于实时计算的场景较多。

**6）Oozie：**Oozie是一个管理Hadoop作业（job）的工作流程调度管理系统。

**7）Hbase：**HBase是一个分布式的、面向列的开源数据库。HBase不同于一般的关系数据库，它是一个适合于非结构化数据存储的数据库。

**8）Hive：**Hive是基于Hadoop的一个数据仓库工具，可以将结构化的数据文件映射为一张数据库表，并提供简单的SQL查询功能，可以将SQL语句转换为MapReduce任务进行运行。其优点是学习成本低，可以通过类SQL语句快速实现简单的MapReduce统计，不必开发专门的MapReduce应用，十分适合数据仓库的统计分析。

**9）ZooKeeper：**它是一个针对大型分布式系统的可靠协调系统，提供的功能包括：配置维护、名字服务、分布式同步、组服务等。